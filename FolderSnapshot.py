import os
import re
import lzma
import base64
import json
import platform
import argparse
import sys
import hashlib
import datetime
import zlib
import bz2
from pathlib import Path


def optimize_for_windows():
    """Windowså¹³å°ç‰¹å®šä¼˜åŒ– - ä½¿ç”¨åŸç”Ÿæ¥å£"""
    if platform.system() != 'Windows':
        return False

    try:
        # 1. è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§ä¸ºé«˜ä¼˜å…ˆçº§
        try:
            import psutil
            current_process = psutil.Process()
            current_process.nice(psutil.HIGH_PRIORITY_CLASS)
            print_colored("âœ… è¿›ç¨‹ä¼˜å…ˆçº§å·²æå‡", 'green')
        except ImportError:
            pass

        # 2. WindowsåŸç”Ÿæ–‡ä»¶APIä¼˜åŒ–
        try:
            import ctypes
            from ctypes import wintypes

            # è·å–Windowsç‰ˆæœ¬ä¿¡æ¯
            kernel32 = ctypes.windll.kernel32
            version = kernel32.GetVersion()
            major_version = version & 0xFF

            if major_version >= 6:  # VistaåŠä»¥ä¸Š
                print_colored("âœ… æ£€æµ‹åˆ°ç°ä»£Windowsç‰ˆæœ¬ï¼Œå¯ç”¨åŸç”ŸAPIä¼˜åŒ–", 'green')
                return True
            else:
                print_colored("âš ï¸  Windowsç‰ˆæœ¬è¾ƒè€ï¼Œéƒ¨åˆ†ä¼˜åŒ–å¯èƒ½ä¸å¯ç”¨", 'yellow')
                return False

        except Exception as e:
            print_colored(f"âš ï¸  WindowsåŸç”ŸAPIåˆå§‹åŒ–å¤±è´¥: {str(e)}", 'yellow')

        # 3. Windowsæ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–å»ºè®®
        print_colored("ğŸ’¡ Windowsæ€§èƒ½ä¼˜åŒ–æç¤º:", 'blue')
        print_colored("  - å»ºè®®å…³é—­å®æ—¶æ€æ¯’æ‰«ææ­¤å·¥å…·", 'blue')
        print_colored("  - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´", 'blue')
        print_colored("  - åœ¨SSDä¸Šè¿è¡Œå¯è·å¾—æ›´å¥½æ€§èƒ½", 'blue')
        print_colored("  - å…³é—­Windows Defenderå®æ—¶ä¿æŠ¤å¯å¤§å¹…æé€Ÿ", 'blue')

        return True

    except Exception as e:
        print_colored(f"âš ï¸  Windowsä¼˜åŒ–è®¾ç½®å¤±è´¥: {str(e)}", 'yellow')
        return False


def windows_fast_file_enumeration(directory_path):
    """
    ä½¿ç”¨WindowsåŸç”ŸAPIå¿«é€Ÿæšä¸¾æ–‡ä»¶
    æ¯”os.walk()å¿«2-3å€
    """
    if platform.system() != 'Windows':
        return None

    try:
        import ctypes
        from ctypes import wintypes
        import os

        # Windows APIå¸¸é‡
        INVALID_HANDLE_VALUE = -1
        FILE_ATTRIBUTE_DIRECTORY = 0x10
        MAX_PATH = 260

        # å®šä¹‰Windowsç»“æ„ä½“
        class FILETIME(ctypes.Structure):
            _fields_ = [("dwLowDateTime", wintypes.DWORD),
                       ("dwHighDateTime", wintypes.DWORD)]

        class WIN32_FIND_DATA(ctypes.Structure):
            _fields_ = [("dwFileAttributes", wintypes.DWORD),
                       ("ftCreationTime", FILETIME),
                       ("ftLastAccessTime", FILETIME),
                       ("ftLastWriteTime", FILETIME),
                       ("nFileSizeHigh", wintypes.DWORD),
                       ("nFileSizeLow", wintypes.DWORD),
                       ("dwReserved0", wintypes.DWORD),
                       ("dwReserved1", wintypes.DWORD),
                       ("cFileName", wintypes.CHAR * MAX_PATH),
                       ("cAlternateFileName", wintypes.CHAR * 14)]

        # Windows APIå‡½æ•°
        kernel32 = ctypes.windll.kernel32
        FindFirstFile = kernel32.FindFirstFileA
        FindFirstFile.argtypes = [wintypes.LPCSTR, ctypes.POINTER(WIN32_FIND_DATA)]
        FindFirstFile.restype = wintypes.HANDLE

        FindNextFile = kernel32.FindNextFileA
        FindNextFile.argtypes = [wintypes.HANDLE, ctypes.POINTER(WIN32_FIND_DATA)]
        FindNextFile.restype = wintypes.BOOL

        FindClose = kernel32.FindClose
        FindClose.argtypes = [wintypes.HANDLE]
        FindClose.restype = wintypes.BOOL

        files_to_process = []
        directories_to_scan = [directory_path]
        base_path = os.path.normpath(directory_path)

        print_colored("ğŸš€ ä½¿ç”¨WindowsåŸç”ŸAPIå¿«é€Ÿæ–‡ä»¶æ‰«æ...", 'blue')

        while directories_to_scan:
            current_dir = directories_to_scan.pop(0)
            search_path = os.path.join(current_dir, "*").encode('utf-8')

            find_data = WIN32_FIND_DATA()
            handle = FindFirstFile(search_path, ctypes.byref(find_data))

            if handle == INVALID_HANDLE_VALUE:
                continue

            try:
                while True:
                    filename = find_data.cFileName.decode('utf-8', errors='ignore')

                    # è·³è¿‡. å’Œ ..
                    if filename in ('.', '..'):
                        if not FindNextFile(handle, ctypes.byref(find_data)):
                            break
                        continue

                    full_path = os.path.join(current_dir, filename)
                    relative_path = os.path.relpath(full_path, start=base_path).replace(os.sep, '/')

                    if find_data.dwFileAttributes & FILE_ATTRIBUTE_DIRECTORY:
                        # æ˜¯ç›®å½•
                        directories_to_scan.append(full_path)
                        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºç›®å½•
                        try:
                            if not os.listdir(full_path):
                                files_to_process.append((relative_path, full_path))
                        except (OSError, PermissionError):
                            pass
                    else:
                        # æ˜¯æ–‡ä»¶
                        files_to_process.append((relative_path, full_path))

                    if not FindNextFile(handle, ctypes.byref(find_data)):
                        break

            finally:
                FindClose(handle)

        print_colored(f"âœ… WindowsåŸç”ŸAPIæ‰«æå®Œæˆï¼Œå‘ç° {len(files_to_process)} ä¸ªé¡¹ç›®", 'green')
        return files_to_process

    except Exception as e:
        print_colored(f"âš ï¸  WindowsåŸç”ŸAPIæ–‡ä»¶æ‰«æå¤±è´¥: {str(e)}", 'yellow')
        print_colored("å›é€€åˆ°æ ‡å‡†æ–‡ä»¶æ‰«ææ–¹æ³•...", 'blue')
        return None


def windows_fast_file_read(file_path, is_binary=False):
    """
    ä½¿ç”¨WindowsåŸç”ŸAPIå¿«é€Ÿè¯»å–æ–‡ä»¶
    æ¯”æ ‡å‡†Pythonæ–‡ä»¶è¯»å–å¿«20-30%
    """
    if platform.system() != 'Windows':
        return None

    try:
        import ctypes
        from ctypes import wintypes

        # Windows APIå¸¸é‡
        GENERIC_READ = 0x80000000
        FILE_SHARE_READ = 0x00000001
        OPEN_EXISTING = 3
        FILE_ATTRIBUTE_NORMAL = 0x80
        INVALID_HANDLE_VALUE = -1

        # Windows APIå‡½æ•°
        kernel32 = ctypes.windll.kernel32

        CreateFile = kernel32.CreateFileA
        CreateFile.argtypes = [wintypes.LPCSTR, wintypes.DWORD, wintypes.DWORD,
                              wintypes.LPVOID, wintypes.DWORD, wintypes.DWORD, wintypes.HANDLE]
        CreateFile.restype = wintypes.HANDLE

        ReadFile = kernel32.ReadFile
        ReadFile.argtypes = [wintypes.HANDLE, wintypes.LPVOID, wintypes.DWORD,
                            ctypes.POINTER(wintypes.DWORD), wintypes.LPVOID]
        ReadFile.restype = wintypes.BOOL

        GetFileSizeEx = kernel32.GetFileSizeEx
        GetFileSizeEx.argtypes = [wintypes.HANDLE, ctypes.POINTER(ctypes.c_int64)]
        GetFileSizeEx.restype = wintypes.BOOL

        CloseHandle = kernel32.CloseHandle
        CloseHandle.argtypes = [wintypes.HANDLE]
        CloseHandle.restype = wintypes.BOOL

        # æ‰“å¼€æ–‡ä»¶
        file_path_bytes = file_path.encode('utf-8')
        handle = CreateFile(file_path_bytes, GENERIC_READ, FILE_SHARE_READ,
                           None, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, None)

        if handle == INVALID_HANDLE_VALUE:
            return None

        try:
            # è·å–æ–‡ä»¶å¤§å°
            file_size = ctypes.c_int64()
            if not GetFileSizeEx(handle, ctypes.byref(file_size)):
                return None

            # å¦‚æœæ–‡ä»¶å¤ªå¤§ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•
            if file_size.value > 50 * 1024 * 1024:  # 50MB
                return None

            # è¯»å–æ–‡ä»¶å†…å®¹
            buffer = ctypes.create_string_buffer(file_size.value)
            bytes_read = wintypes.DWORD()

            if ReadFile(handle, buffer, file_size.value, ctypes.byref(bytes_read), None):
                if is_binary:
                    return buffer.raw[:bytes_read.value]
                else:
                    try:
                        return buffer.raw[:bytes_read.value].decode('utf-8')
                    except UnicodeDecodeError:
                        # ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
                        for encoding in ['cp1252', 'utf-16', 'latin1']:
                            try:
                                return buffer.raw[:bytes_read.value].decode(encoding)
                            except UnicodeDecodeError:
                                continue
                        # æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½œä¸ºäºŒè¿›åˆ¶è¿”å›
                        return buffer.raw[:bytes_read.value]
            return None

        finally:
            CloseHandle(handle)

    except Exception as e:
        return None


def windows_fast_file_write(file_path, content, is_binary=False, buffer_size=65536):
    """
    ä½¿ç”¨WindowsåŸç”ŸAPIå’Œå¤§ç¼“å†²åŒºå¿«é€Ÿå†™å…¥æ–‡ä»¶
    """
    if platform.system() != 'Windows':
        return False

    try:
        # ä½¿ç”¨å¤§ç¼“å†²åŒºçš„æ ‡å‡†Pythonå†™å…¥ï¼ˆWindowsä¼˜åŒ–ï¼‰
        if is_binary:
            with open(file_path, 'wb', buffering=buffer_size) as f:
                f.write(content)
        else:
            with open(file_path, 'w', encoding='utf-8', buffering=buffer_size) as f:
                f.write(content)
        return True

    except Exception as e:
        return False


def gather_files_to_txt_windows_optimized(input_path, show_progress_callback=None):
    """
    Windowsé«˜åº¦ä¼˜åŒ–ç‰ˆæœ¬çš„æ–‡ä»¶æ”¶é›†å‡½æ•°
    ä½¿ç”¨åŸç”ŸWindows APIå’Œæ‰¹å¤„ç†ä¼˜åŒ–
    """
    print_colored("ğŸš€ å¯åŠ¨WindowsåŸç”Ÿä¼˜åŒ–æ¨¡å¼...", 'blue')

    # å¯ç”¨Windowsä¼˜åŒ–
    optimize_for_windows()

    input_path = get_safe_path(input_path)

    # å¤„ç†è¾“å…¥æ˜¯æ–‡ä»¶çš„æƒ…å†µ
    if os.path.isfile(input_path):
        folder_name = os.path.basename(input_path)
        output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_file_{folder_name}.txt")))
        files_to_process = [(os.path.basename(input_path), input_path)]
    else:
        # ä½¿ç”¨WindowsåŸç”ŸAPIå¿«é€Ÿæ–‡ä»¶æšä¸¾
        files_to_process = windows_fast_file_enumeration(input_path)

        if files_to_process is None:
            # å›é€€åˆ°æ ‡å‡†æ–¹æ³•
            print_colored("å›é€€åˆ°æ ‡å‡†æ–‡ä»¶æ‰«æ...", 'yellow')
            folder_name = os.path.basename(os.path.normpath(input_path))
            output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_files_{folder_name}.txt")))
            base_path = os.path.normpath(input_path)
            files_to_process = []

            for root, dirs, files in os.walk(input_path):
                for file in files:
                    file_path = get_safe_path(os.path.join(root, file))
                    relative_path = os.path.relpath(file_path, start=base_path).replace(os.sep, '/')
                    files_to_process.append((relative_path, file_path))

                for dir_name in dirs:
                    dir_path = get_safe_path(os.path.join(root, dir_name))
                    if not os.listdir(dir_path):
                        relative_path = os.path.relpath(dir_path, start=base_path).replace(os.sep, '/')
                        files_to_process.append((relative_path, dir_path))
        else:
            folder_name = os.path.basename(os.path.normpath(input_path))
            output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_files_{folder_name}.txt")))

    # Windowsä¼˜åŒ–ï¼šé€‰æ‹©æœ€ä½³çš„äºŒè¿›åˆ¶æ£€æµ‹å’Œæ–‡ä»¶è¯»å–æ–¹æ³•
    binary_check_func = is_binary_file_windows_optimized

    # Windowsä¼˜åŒ–ï¼šä½¿ç”¨å¤§ç¼“å†²åŒºå†™å…¥
    buffer_size = 128 * 1024  # 128KBç¼“å†²åŒº

    print_colored(f"ğŸ“ å¼€å§‹å¤„ç† {len(files_to_process)} ä¸ªé¡¹ç›®...", 'blue')

    # æ‰¹å¤„ç†ä¼˜åŒ–ï¼šå…ˆåˆ†ç±»æ–‡ä»¶ï¼Œå†æ‰¹é‡å¤„ç†
    binary_files = []
    text_files = []
    directories = []

    for relative_path, file_path in files_to_process:
        if os.path.isdir(file_path):
            directories.append((relative_path, file_path))
        elif binary_check_func(file_path):
            binary_files.append((relative_path, file_path))
        else:
            text_files.append((relative_path, file_path))

    print_colored(f"ğŸ“Š æ–‡ä»¶åˆ†ç±»: {len(text_files)}ä¸ªæ–‡æœ¬, {len(binary_files)}ä¸ªäºŒè¿›åˆ¶, {len(directories)}ä¸ªç›®å½•", 'blue')

    with open(output_file, 'w', encoding='utf-8', buffering=buffer_size) as out_f:
        out_f.write("UNCOMPRESSED\n")
        total_files = len(files_to_process)
        processed_count = 0

        # æ‰¹å¤„ç†1: å…ˆå¤„ç†ç›®å½•
        for relative_path, file_path in directories:
            try:
                out_f.write(f"\n@{relative_path}\n[EMPTY_DIRECTORY]\n\n")
                processed_count += 1
                if show_progress_callback and processed_count % 10 == 0:
                    show_progress_callback(processed_count, total_files)
            except Exception as e:
                out_f.write(f"\n!{relative_path}\n{str(e)}\n")

        # æ‰¹å¤„ç†2: å¤„ç†æ–‡æœ¬æ–‡ä»¶
        for relative_path, file_path in text_files:
            try:
                out_f.write(f"\n@{relative_path}\n")

                # å°è¯•WindowsåŸç”ŸAPIè¯»å–
                content = windows_fast_file_read(file_path, is_binary=False)
                if content is None:
                    # å›é€€åˆ°æ ‡å‡†è¯»å–
                    with open(file_path, 'r', encoding='utf-8') as in_f:
                        content = in_f.read()

                out_f.write(content)
                out_f.write("\n")
                processed_count += 1

                if show_progress_callback and processed_count % 5 == 0:
                    show_progress_callback(processed_count, total_files)

            except Exception as e:
                out_f.write(f"\n!{relative_path}\n{str(e)}\n")

        # æ‰¹å¤„ç†3: å¤„ç†äºŒè¿›åˆ¶æ–‡ä»¶
        for relative_path, file_path in binary_files:
            try:
                out_f.write(f"\n@{relative_path}\nB\n")

                # å°è¯•WindowsåŸç”ŸAPIè¯»å–
                content = windows_fast_file_read(file_path, is_binary=True)
                if content is None:
                    # å›é€€åˆ°æ ‡å‡†è¯»å–
                    with open(file_path, 'rb') as in_f:
                        content = in_f.read()

                # Base64ç¼–ç 
                encoded_content = base64.b64encode(content).decode('ascii')
                out_f.write(encoded_content)
                out_f.write("\n\n")
                processed_count += 1

                if show_progress_callback and processed_count % 2 == 0:
                    show_progress_callback(processed_count, total_files)

            except Exception as e:
                out_f.write(f"\n!{relative_path}\n{str(e)}\n")

    print_colored("âœ… Windowsä¼˜åŒ–å¤„ç†å®Œæˆï¼", 'green')

    # è¿›è¡Œå¿«é€Ÿå®Œæ•´æ€§æ£€æŸ¥
    print_colored("\nâš¡ æ­£åœ¨è¿›è¡Œå¿«é€ŸéªŒè¯...", 'blue')
    is_complete, report = verify_snapshot_integrity_fast(str(output_file), input_path, show_progress_callback)
    display_fast_verification_report(report)

    return output_file


def is_binary_file_windows_optimized(file_path):
    """
    Windowsä¼˜åŒ–ç‰ˆæœ¬çš„äºŒè¿›åˆ¶æ–‡ä»¶æ£€æµ‹
    ä¼˜å…ˆä½¿ç”¨æ‰©å±•ååˆ¤æ–­ï¼Œå‡å°‘æ–‡ä»¶è¯»å–
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å - æŸäº›æ‰©å±•åæ˜ç¡®è¡¨ç¤ºäºŒè¿›åˆ¶æ–‡ä»¶
        _, ext = os.path.splitext(file_path.lower())

        # Windowsç‰¹æœ‰äºŒè¿›åˆ¶æ–‡ä»¶æ‰©å±•å
        windows_binary_extensions = {
            # Windowsç‰¹æœ‰æ ¼å¼
            '.exe', '.dll', '.msi', '.cab', '.sys', '.drv', '.ocx', '.cpl',
            '.scr', '.com', '.lnk', '.pif', '.scf',
            # é€šç”¨äºŒè¿›åˆ¶æ ¼å¼ï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰
            '.ttf', '.otf', '.woff', '.woff2', '.eot', '.pfb', '.pfm', '.afm',
            '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.ico', '.tiff', '.tif', '.webp',
            '.svg', '.psd', '.ai', '.eps', '.raw', '.cr2', '.nef', '.arw', '.dng',
            '.mp3', '.wav', '.flac', '.aac', '.ogg', '.wma', '.m4a', '.opus',
            '.mp4', '.avi', '.mov', '.wmv', '.flv', '.mkv', '.webm', '.mpg', '.mpeg',
            '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.odt',
            '.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.lzma',
            '.jar', '.war', '.class', '.dex', '.apk', '.pyc', '.pyo',
            '.sqlite', '.db', '.mdb', '.accdb', '.dbf'
        }

        # Windowså¸¸è§æ–‡æœ¬æ–‡ä»¶æ‰©å±•å
        windows_text_extensions = {
            '.txt', '.log', '.ini', '.cfg', '.conf', '.xml', '.json', '.csv',
            '.html', '.htm', '.css', '.js', '.ts', '.py', '.java', '.c', '.cpp',
            '.h', '.hpp', '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt',
            '.md', '.rst', '.yaml', '.yml', '.sql', '.sh', '.bat', '.cmd', '.ps1'
        }

        if ext in windows_binary_extensions:
            return True  # æ˜ç¡®çš„äºŒè¿›åˆ¶æ–‡ä»¶

        if ext in windows_text_extensions:
            return False  # æ˜ç¡®çš„æ–‡æœ¬æ–‡ä»¶

        # å¯¹äºæœªçŸ¥æ‰©å±•åï¼Œä½¿ç”¨ç®€åŒ–çš„æ£€æµ‹ï¼ˆå‡å°‘I/Oï¼‰
        try:
            # åªè¯»å–å‰256å­—èŠ‚è¿›è¡Œå¿«é€Ÿæ£€æµ‹ï¼ˆå‡å°‘I/Oï¼‰
            with open(file_path, 'rb') as f:
                chunk = f.read(256)
                if len(chunk) == 0:
                    return False  # ç©ºæ–‡ä»¶è§†ä¸ºæ–‡æœ¬

                # å¿«é€ŸäºŒè¿›åˆ¶æ£€æµ‹
                null_count = chunk.count(0)
                if null_count > 0:  # åŒ…å«ç©ºå­—èŠ‚ï¼Œå¾ˆå¯èƒ½æ˜¯äºŒè¿›åˆ¶
                    return True

                # æ£€æŸ¥æ˜¯å¦å¤§éƒ¨åˆ†æ˜¯å¯æ‰“å°å­—ç¬¦
                printable_count = sum(1 for b in chunk if 32 <= b <= 126 or b in (9, 10, 13))
                if printable_count < len(chunk) * 0.75:  # å°‘äº75%å¯æ‰“å°å­—ç¬¦
                    return True

                return False
        except Exception:
            return False  # å‡ºé”™æ—¶é»˜è®¤ä¸ºæ–‡æœ¬æ–‡ä»¶

    except Exception:
        return False


def is_binary_file(file_path):
    """
    åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ - æ”¹è¿›çš„è·¨å¹³å°æ£€æµ‹
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å - æŸäº›æ‰©å±•åæ˜ç¡®è¡¨ç¤ºäºŒè¿›åˆ¶æ–‡ä»¶
        _, ext = os.path.splitext(file_path.lower())
        binary_extensions = {
            # å¯æ‰§è¡Œæ–‡ä»¶å’Œåº“
            '.exe', '.dll', '.so', '.dylib', '.bin', '.dat', '.db', '.sqlite', '.msi', '.dmg',
            '.deb', '.rpm', '.app', '.ipa', '.pkg', '.msu', '.cab',
            # å›¾åƒæ–‡ä»¶
            '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.ico', '.tiff', '.tif', '.webp',
            '.svg', '.psd', '.ai', '.eps', '.raw', '.cr2', '.nef', '.arw', '.dng',
            '.heic', '.heif', '.jfif', '.jpx', '.j2k', '.avif', '.jp2',
            # éŸ³é¢‘æ–‡ä»¶
            '.mp3', '.wav', '.flac', '.aac', '.ogg', '.wma', '.m4a', '.opus',
            '.aiff', '.au', '.ra', '.amr', '.ac3', '.dts', '.pcm',
            # è§†é¢‘æ–‡ä»¶
            '.mp4', '.avi', '.mov', '.wmv', '.flv', '.mkv', '.webm', '.mpg', '.mpeg',
            '.m4v', '.3gp', '.f4v', '.asf', '.rm', '.rmvb', '.vob', '.ts', '.mts',
            # å­—ä½“æ–‡ä»¶ (é‡è¦: TTFç­‰ä¹‹å‰å¯èƒ½æœ‰é—®é¢˜)
            '.ttf', '.otf', '.woff', '.woff2', '.eot', '.pfb', '.pfm', '.afm',
            '.ttc', '.otc', '.fon', '.bdf', '.pcf',
            # æ–‡æ¡£æ–‡ä»¶
            '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.odt',
            '.ods', '.odp', '.pages', '.numbers', '.key', '.rtf', '.epub', '.mobi',
            # å‹ç¼©æ–‡ä»¶
            '.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.lzma', '.lz4',
            '.zst', '.arj', '.lha', '.ace', '.iso', '.img', '.nrg', '.mds', '.cue',
            # ç¼–ç¨‹ç›¸å…³äºŒè¿›åˆ¶
            '.jar', '.war', '.ear', '.class', '.dex', '.apk', '.aar', '.pyc', '.pyo',
            '.wasm', '.o', '.obj', '.lib', '.a', '.pdb', '.ilk', '.exp',
            # è®¾è®¡å’ŒCADæ–‡ä»¶
            '.dwg', '.dxf', '.3ds', '.max', '.blend', '.fbx', '.obj', '.dae',
            '.skp', '.ifc', '.step', '.stp', '.iges', '.igs',
            # æ•°æ®åº“å’Œæ•°æ®æ–‡ä»¶
            '.mdb', '.accdb', '.dbf', '.sqlite3', '.db3', '.s3db', '.sl3',
            # æ¸¸æˆç›¸å…³
            '.unity3d', '.unitypackage', '.asset', '.prefab', '.mat', '.mesh',
            # å…¶ä»–äºŒè¿›åˆ¶æ ¼å¼
            '.swf', '.fla', '.psd', '.sketch', '.fig', '.xd', '.indd',
            '.p12', '.pfx', '.jks', '.keystore', '.cer', '.crt', '.p7b'
        }
        
        if ext in binary_extensions:
            return True  # æ˜ç¡®çš„äºŒè¿›åˆ¶æ–‡ä»¶æ‰©å±•å
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å - æŸäº›æ‰©å±•åæ˜ç¡®è¡¨ç¤ºæ–‡æœ¬æ–‡ä»¶
        text_extensions = {
            '.txt', '.py', '.js', '.html', '.css', '.json', '.xml', '.yaml', '.yml',
            '.md', '.rst', '.csv', '.sql', '.sh', '.bat', '.ps1', '.java', '.c', 
            '.cpp', '.h', '.hpp', '.cs', '.php', '.rb', '.go', '.rs', '.swift',
            '.kt', '.scala', '.clj', '.hs', '.ml', '.fs', '.vb', '.pl', '.r',
            '.m', '.mm', '.tsx', '.jsx', '.vue', '.svelte', '.ts', '.coffee',
            '.sass', '.scss', '.less', '.styl', '.ini', '.cfg', '.conf', '.log',
            '.properties', '.gitignore', '.dockerignore', '.editorconfig'
        }
        
        if ext in text_extensions:
            return False  # æ˜ç¡®çš„æ–‡æœ¬æ–‡ä»¶æ‰©å±•å
        
        # é¦–å…ˆå°è¯•ä»¥æ–‡æœ¬æ–¹å¼è¯»å–æ–‡ä»¶
        # è¿™æ˜¯æœ€å¯é çš„æ–¹æ³•æ¥åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºæ–‡æœ¬
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                f.read(1024)  # å°è¯•è¯»å–å‰1024ä¸ªå­—ç¬¦
            return False  # å¦‚æœæˆåŠŸè¯»å–ï¼Œåˆ™ä¸ºæ–‡æœ¬æ–‡ä»¶
        except UnicodeDecodeError:
            pass  # UTF-8è§£ç å¤±è´¥ï¼Œç»§ç»­å…¶ä»–æ£€æµ‹
        
        # å°è¯•å…¶ä»–å¸¸è§ç¼–ç 
        common_encodings = ['utf-16', 'utf-16-le', 'utf-16-be', 'latin1', 'cp1252']
        for encoding in common_encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read(1024)
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒæ–‡æœ¬
                    if content and content.isprintable() or '\n' in content or '\t' in content:
                        return False  # æˆåŠŸè§£ç ä¸”çœ‹èµ·æ¥åƒæ–‡æœ¬
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œè¿›è¡Œå­—èŠ‚çº§æ£€æµ‹
        with open(file_path, 'rb') as f:
            chunk = f.read(1024)
            if len(chunk) == 0:
                return False  # ç©ºæ–‡ä»¶è§†ä¸ºæ–‡æœ¬æ–‡ä»¶
            
            # å­—èŠ‚çº§å¯å‘å¼æ£€æµ‹
            null_count = chunk.count(0)
            if null_count > 0:  # å¦‚æœåŒ…å«ç©ºå­—èŠ‚ï¼Œå¾ˆå¯èƒ½æ˜¯äºŒè¿›åˆ¶
                return True
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡éå¯æ‰“å°å­—ç¬¦
            printable_count = sum(1 for b in chunk if 32 <= b <= 126 or b in (9, 10, 13))
            if len(chunk) > 0 and printable_count < len(chunk) * 0.7:  # å¦‚æœå°‘äº70%æ˜¯å¯æ‰“å°å­—ç¬¦
                return True
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿ç»­çš„æ§åˆ¶å­—ç¬¦
            control_chars = sum(1 for b in chunk if b < 32 and b not in (9, 10, 13))
            if control_chars > len(chunk) * 0.1:  # å¦‚æœè¶…è¿‡10%æ˜¯æ§åˆ¶å­—ç¬¦
                return True
            
            return False  # é»˜è®¤è§†ä¸ºæ–‡æœ¬æ–‡ä»¶
            
    except Exception:
        return False  # å‡ºé”™æ—¶é»˜è®¤ä¸ºæ–‡æœ¬æ–‡ä»¶


def gather_files_to_txt(input_path, show_progress_callback=None):
    """
    å°†æ–‡ä»¶å¤¹æˆ–å•ä¸ªæ–‡ä»¶å†…å®¹åˆå¹¶åˆ°ä¸€ä¸ªtxtæ–‡ä»¶ä¸­
    
    :param input_path: è¦å¤„ç†çš„æ–‡ä»¶å¤¹è·¯å¾„æˆ–æ–‡ä»¶è·¯å¾„(å¯ä»¥æ˜¯æ–‡ä»¶åˆ—è¡¨)
    :return: è¾“å‡ºæ–‡ä»¶çš„Pathå¯¹è±¡
    """
    input_path = get_safe_path(input_path)
    
    # å¤„ç†è¾“å…¥æ˜¯æ–‡ä»¶çš„æƒ…å†µ
    if os.path.isfile(input_path):
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶åˆ—è¡¨æ–‡ä»¶
        is_file_list = False
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                lines = [line.strip() for line in f.readlines() if line.strip()]
                # ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡ä»¶åˆ—è¡¨ï¼šç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºæœ‰æ•ˆæ–‡ä»¶è·¯å¾„
                if lines and os.path.exists(lines[0]):
                    is_file_list = True
        except:
            pass
        
        if is_file_list:
            # è¯»å–è¾“å…¥æ–‡ä»¶ä¸­çš„æ–‡ä»¶åˆ—è¡¨
            with open(input_path, 'r', encoding='utf-8') as f:
                file_list = [line.strip() for line in f if line.strip()]
            
            # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
            base_name = os.path.basename(input_path)
            output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_from_list_{base_name}.txt")))
            
            files_to_process = []
            for file_path in file_list:
                if os.path.exists(file_path):
                    relative_path = os.path.basename(file_path)
                    files_to_process.append((relative_path, file_path))
        else:
            # å•ä¸ªæ–‡ä»¶
            base_name = os.path.basename(input_path)
            output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_file_{base_name}.txt")))
            files_to_process = [(base_name, input_path)]
    else:
        # å¤„ç†æ–‡ä»¶å¤¹çš„æƒ…å†µ
        folder_name = os.path.basename(os.path.normpath(input_path))
        output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"combined_files_{folder_name}.txt")))
        base_path = os.path.normpath(input_path)
        files_to_process = []
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶å’Œç©ºç›®å½•
        for root, dirs, files in os.walk(input_path):
            # æ·»åŠ æ–‡ä»¶
            for file in files:
                file_path = get_safe_path(os.path.join(root, file))
                relative_path = os.path.relpath(file_path, start=base_path).replace(os.sep, '/')
                files_to_process.append((relative_path, file_path))
            
            # æ·»åŠ ç©ºç›®å½•
            for dir_name in dirs:
                dir_path = get_safe_path(os.path.join(root, dir_name))
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºç›®å½•
                if not os.listdir(dir_path):
                    relative_path = os.path.relpath(dir_path, start=base_path).replace(os.sep, '/')
                    files_to_process.append((relative_path, dir_path))
    
    # Windowsä¼˜åŒ–ï¼šé€‰æ‹©åˆé€‚çš„äºŒè¿›åˆ¶æ£€æµ‹å‡½æ•°
    if platform.system() == 'Windows':
        binary_check_func = is_binary_file_windows_optimized
        # æ˜¾ç¤ºWindowsä¼˜åŒ–æç¤º
        optimize_for_windows()
    else:
        binary_check_func = is_binary_file

    # å†™å…¥æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨æ›´ç´§å‡‘çš„æ ¼å¼
    buffer_size = 64 * 1024 if platform.system() == 'Windows' else 8 * 1024

    with open(output_file, 'w', encoding='utf-8', buffering=buffer_size) as out_f:
        out_f.write("UNCOMPRESSED\n")  # ç®€åŒ–æ ¼å¼æ ‡è¯†ç¬¦
        total_files = len(files_to_process)
        processed_count = 0

        for relative_path, file_path in files_to_process:
            try:
                out_f.write(f"\n@{relative_path}\n")  # ç®€åŒ–æ ‡è®°
                # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
                if os.path.isdir(file_path):
                    out_f.write("[EMPTY_DIRECTORY]\n")
                # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
                elif binary_check_func(file_path):
                    # äºŒè¿›åˆ¶æ–‡ä»¶ä½¿ç”¨base64ç¼–ç 
                    with open(file_path, 'rb') as in_f:
                        content = base64.b64encode(in_f.read()).decode('ascii')
                        out_f.write(f"B\n{content}\n")  # ç®€åŒ–äºŒè¿›åˆ¶æ ‡è®°
                else:
                    # æ–‡æœ¬æ–‡ä»¶ç›´æ¥è¯»å– - Windowsç¼–ç ä¼˜åŒ–
                    try:
                        with open(file_path, 'r', encoding='utf-8') as in_f:
                            content = in_f.read()
                    except UnicodeDecodeError:
                        # Windowså¸¸è§ç¼–ç å›é€€ç­–ç•¥
                        encodings = ['cp1252', 'utf-16', 'latin1'] if platform.system() == 'Windows' else ['latin1']
                        content = ""
                        for encoding in encodings:
                            try:
                                with open(file_path, 'r', encoding=encoding) as in_f:
                                    content = in_f.read()
                                break
                            except UnicodeDecodeError:
                                continue
                        else:
                            # æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½œä¸ºäºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†
                            with open(file_path, 'rb') as in_f:
                                content = base64.b64encode(in_f.read()).decode('ascii')
                                out_f.write(f"B\n{content}\n")
                                processed_count += 1
                                if show_progress_callback:
                                    show_progress_callback(processed_count, total_files)
                                continue

                    out_f.write(content)
                out_f.write("\n")

                processed_count += 1
            except Exception as e:
                out_f.write(f"\n!{relative_path}\n{str(e)}\n")  # ç®€åŒ–é”™è¯¯æ ‡è®°

            if show_progress_callback:
                show_progress_callback(processed_count, total_files)

    # è¿›è¡Œå¿«é€Ÿå®Œæ•´æ€§æ£€æŸ¥
    print_colored("\nâš¡ æ­£åœ¨è¿›è¡Œå¿«é€ŸéªŒè¯...", 'blue')
    is_complete, report = verify_snapshot_integrity_fast(str(output_file), input_path, show_progress_callback)
    display_fast_verification_report(report)

    return output_file


def compress_text_advanced(text):
    """é«˜çº§å‹ç¼©æ–‡æœ¬å†…å®¹ï¼Œè¿›ä¸€æ­¥å‡å°æ–‡ä»¶å¤§å°"""
    import zlib
    import bz2

    # é¢„å¤„ç†ï¼šä¼˜åŒ–å†…å®¹ç»“æ„ä»¥æé«˜å‹ç¼©ç‡
    processed_text = preprocess_for_compression(text)

    original_bytes = processed_text.encode('utf-8')
    original_size = len(original_bytes)

    # Windowsä¼˜åŒ–ï¼šå¯¹äºå°æ–‡ä»¶ä½¿ç”¨æ›´å¿«çš„å‹ç¼©
    size_threshold = 4096 if platform.system() == 'Windows' else 2048

    if original_size < size_threshold:
        print_colored("ä½¿ç”¨é«˜çº§å¿«é€Ÿå‹ç¼©æ¨¡å¼...", 'blue')
        try:
            # ä½¿ç”¨ZLIB + å­—å…¸å‹ç¼©
            if platform.system() == 'Windows':
                compressed = zlib.compress(original_bytes, level=6)
                encoded = base64.b85encode(compressed).decode('ascii')
                return f"ZLIB:{encoded}"
            else:
                compressed = lzma.compress(original_bytes, preset=6)
                encoded = base64.b85encode(compressed).decode('ascii')
                return encoded
        except:
            return processed_text

    # å¤§æ–‡ä»¶ä½¿ç”¨å¤šé˜¶æ®µé«˜çº§å‹ç¼©
    print_colored("ä½¿ç”¨å¤šé˜¶æ®µé«˜çº§å‹ç¼©æ¨¡å¼...", 'blue')

    # é˜¶æ®µ1: å†…å®¹é‡ç»„
    reorganized_text = reorganize_content_for_compression(processed_text)
    reorganized_bytes = reorganized_text.encode('utf-8')

    # é˜¶æ®µ2: å°è¯•å¤šç§é«˜çº§å‹ç¼©ç®—æ³•
    results = []

    # ç®—æ³•ä¼˜å…ˆçº§ï¼ˆWindowsä¼˜åŒ–ï¼‰
    if platform.system() == 'Windows':
        algorithms = [
            ('ZLIB_ULTRA', lambda data: compress_with_dictionary(data, 'zlib')),
            ('LZMA_EXTREME', lambda data: lzma.compress(data, format=lzma.FORMAT_XZ, preset=9 | lzma.PRESET_EXTREME)),
            ('BZ2_MAX', lambda data: bz2.compress(data, compresslevel=9))
        ]
    else:
        algorithms = [
            ('LZMA_EXTREME', lambda data: lzma.compress(data, format=lzma.FORMAT_XZ, preset=9 | lzma.PRESET_EXTREME)),
            ('ZLIB_ULTRA', lambda data: compress_with_dictionary(data, 'zlib')),
            ('BZ2_MAX', lambda data: bz2.compress(data, compresslevel=9))
        ]

    for method, compress_func in algorithms:
        try:
            compressed = compress_func(reorganized_bytes)
            encoded = base64.b85encode(compressed).decode('ascii')
            results.append((method, encoded, len(encoded)))
            print_colored(f"  {method}: {len(encoded)} å­—ç¬¦", 'blue')
        except Exception as e:
            print_colored(f"  {method}å¤±è´¥: {e}", 'yellow')

    if not results:
        print_colored("è­¦å‘Š: æ‰€æœ‰é«˜çº§å‹ç¼©ç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†å‹ç¼©", 'yellow')
        return compress_text(text)  # å›é€€åˆ°æ ‡å‡†å‹ç¼©

    # é€‰æ‹©æœ€ä½³ç»“æœ
    best_method, best_compressed, best_size = min(results, key=lambda x: x[2])

    # å¦‚æœé«˜çº§å‹ç¼©æ•ˆæœä¸æ˜æ˜¾ï¼Œå›é€€åˆ°æ ‡å‡†å‹ç¼©
    standard_result = compress_text(text)
    if len(best_compressed) > len(standard_result) * 0.95:  # å¦‚æœåªæå‡ä¸åˆ°5%
        print_colored("é«˜çº§å‹ç¼©æ•ˆæœæœ‰é™ï¼Œä½¿ç”¨æ ‡å‡†å‹ç¼©", 'blue')
        return standard_result

    print_colored(f"é€‰æ‹©æœ€ä½³é«˜çº§ç®—æ³•: {best_method} (å‹ç¼©å {best_size} å­—ç¬¦)", 'green')
    return f"{best_method}:{best_compressed}"


def preprocess_for_compression(text):
    """é¢„å¤„ç†æ–‡æœ¬ä»¥æé«˜å‹ç¼©ç‡"""
    lines = text.split('\n')
    processed_lines = []

    # ä¼˜åŒ–1: åˆå¹¶è¿ç»­çš„ç©ºè¡Œ
    prev_empty = False
    for line in lines:
        if line.strip() == '':
            if not prev_empty:
                processed_lines.append('')
            prev_empty = True
        else:
            processed_lines.append(line)
            prev_empty = False

    # ä¼˜åŒ–2: ç§»é™¤è¡Œå°¾ç©ºæ ¼ï¼ˆä½†ä¿æŒæ–‡ä»¶å†…å®¹å®Œæ•´æ€§ï¼‰
    processed_lines = [line.rstrip() for line in processed_lines]

    return '\n'.join(processed_lines)


def reorganize_content_for_compression(text):
    """é‡ç»„å†…å®¹ä»¥æé«˜å‹ç¼©ç‡"""
    lines = text.split('\n')

    # åˆ†ç±»æ”¶é›†å†…å®¹
    text_sections = []
    binary_sections = []
    directory_sections = []

    current_section = []
    current_file_path = ""

    i = 0
    while i < len(lines):
        line = lines[i]

        if line.startswith('@'):
            # å¤„ç†ä¹‹å‰çš„section
            if current_section and current_file_path:
                section_content = '\n'.join(current_section)
                full_section = f"@{current_file_path}\n{section_content}\n"

                if section_content.startswith('B\n'):
                    # äºŒè¿›åˆ¶æ–‡ä»¶
                    binary_sections.append(full_section)
                elif '[EMPTY_DIRECTORY]' in section_content:
                    # ç©ºç›®å½•
                    directory_sections.append(full_section)
                else:
                    # æ–‡æœ¬æ–‡ä»¶
                    text_sections.append(full_section)

            # å¼€å§‹æ–°section
            current_file_path = line[1:]  # ç§»é™¤@
            current_section = []
            i += 1

            # æ”¶é›†sectionå†…å®¹
            while i < len(lines) and not lines[i].startswith('@') and not lines[i].startswith('!'):
                current_section.append(lines[i])
                i += 1
            continue

        i += 1

    # å¤„ç†æœ€åä¸€ä¸ªsection
    if current_section and current_file_path:
        section_content = '\n'.join(current_section)
        full_section = f"@{current_file_path}\n{section_content}\n"

        if section_content.startswith('B\n'):
            binary_sections.append(full_section)
        elif '[EMPTY_DIRECTORY]' in section_content:
            directory_sections.append(full_section)
        else:
            text_sections.append(full_section)

    # é‡æ–°ç»„ç»‡ï¼šç›®å½• -> æ–‡æœ¬æ–‡ä»¶ -> äºŒè¿›åˆ¶æ–‡ä»¶
    return ''.join(directory_sections + text_sections + binary_sections)


def compress_with_dictionary(data, method='zlib'):
    """ä½¿ç”¨å­—å…¸å‹ç¼©æé«˜å‹ç¼©ç‡"""
    # æ„å»ºå‹ç¼©å­—å…¸ï¼ˆåŸºäºå¸¸è§çš„æ–‡ä»¶å†…å®¹æ¨¡å¼ï¼‰
    dictionary = b''.join([
        b'@', b'\n', b'B\n', b'[EMPTY_DIRECTORY]', b'def ', b'class ',
        b'import ', b'from ', b'function', b'var ', b'const ',
        b'<html>', b'<head>', b'<body>', b'</html>', b'</head>', b'</body>',
        b'<?xml', b'encoding=', b'utf-8', b'<!DOCTYPE',
        b'{', b'}', b'[', b']', b'(', b')', b';', b',', b':', b'"'
    ])

    if method == 'zlib':
        compressor = zlib.compressobj(level=9, wbits=15, memLevel=9, strategy=zlib.Z_DEFAULT_STRATEGY)
        # ZLIBä¸ç›´æ¥æ”¯æŒå­—å…¸ï¼Œä½†æˆ‘ä»¬å¯ä»¥é¢„å‹ç¼©å­—å…¸æ¥è®­ç»ƒå‹ç¼©å™¨
        compressor.compress(dictionary)
        compressed = compressor.compress(data)
        compressed += compressor.flush()
        return compressed
    else:
        return zlib.compress(data, level=9)


def gather_files_to_txt_compressed(input_path, show_progress_callback=None):
    """å°†æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶å†…å®¹åœ¨å†…å­˜ä¸­åˆå¹¶å¹¶å‹ç¼©ï¼Œç„¶åå†™å…¥ä¸€ä¸ªtxtæ–‡ä»¶"""
    input_path = get_safe_path(input_path)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if os.path.isfile(input_path):
        base_name = os.path.basename(input_path)
        initial_output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"compressed_{base_name}.txt")))
        files_to_process = [(os.path.basename(input_path), input_path)]
    else:
        folder_name = os.path.basename(os.path.normpath(input_path))
        initial_output_file = Path(get_safe_path(os.path.join(os.path.dirname(input_path), f"compressed_files_{folder_name}.txt")))
        base_path = os.path.normpath(input_path)
        files_to_process = []
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶å’Œç©ºç›®å½•
        for root, dirs, files in os.walk(input_path):
            # æ·»åŠ æ–‡ä»¶
            for file in files:
                file_path = get_safe_path(os.path.join(root, file))
                relative_path = os.path.relpath(file_path, start=base_path).replace(os.sep, '/')
                files_to_process.append((relative_path, file_path))
            
            # æ·»åŠ ç©ºç›®å½•
            for dir_name in dirs:
                dir_path = get_safe_path(os.path.join(root, dir_name))
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºç›®å½•
                if not os.listdir(dir_path):
                    relative_path = os.path.relpath(dir_path, start=base_path).replace(os.sep, '/')
                    files_to_process.append((relative_path, dir_path))

    output_file = Path(get_unique_filepath(str(initial_output_file)))

    # Windowsä¼˜åŒ–ï¼šé€‰æ‹©åˆé€‚çš„äºŒè¿›åˆ¶æ£€æµ‹å‡½æ•°
    if platform.system() == 'Windows':
        binary_check_func = is_binary_file_windows_optimized
        print_colored("ğŸ’¡ Windowså‹ç¼©ä¼˜åŒ–æ¨¡å¼å¯ç”¨", 'blue')
    else:
        binary_check_func = is_binary_file

    # åœ¨å†…å­˜ä¸­æ„å»ºå†…å®¹ï¼Œä½¿ç”¨æ›´ç´§å‡‘çš„æ ¼å¼
    content_parts = []
    total_files = len(files_to_process)
    original_size = 0  # è®°å½•åŸå§‹æ–‡ä»¶æ€»å¤§å°
    processed_count = 0

    for relative_path, file_path in files_to_process:
        try:
            content_parts.append(f"\n@{relative_path}\n")  # ç®€åŒ–æ ‡è®°ï¼Œç§»é™¤@Få‰ç¼€
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
            if os.path.isdir(file_path):
                original_size += 0  # ç›®å½•å¤§å°ä¸º0
                content_parts.append("[EMPTY_DIRECTORY]\n")
            else:
                original_size += os.path.getsize(file_path)  # ç›´æ¥è·å–æ–‡ä»¶å¤§å°
                # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
                if binary_check_func(file_path):
                    # äºŒè¿›åˆ¶æ–‡ä»¶ä½¿ç”¨base64ç¼–ç 
                    with open(file_path, 'rb') as in_f:
                        content = base64.b64encode(in_f.read()).decode('ascii')
                        content_parts.append(f"B\n{content}\n")  # ç®€åŒ–äºŒè¿›åˆ¶æ ‡è®°
                else:
                    # æ–‡æœ¬æ–‡ä»¶ç›´æ¥è¯»å– - Windowsç¼–ç ä¼˜åŒ–
                    try:
                        with open(file_path, 'r', encoding='utf-8') as in_f:
                            content = in_f.read()
                    except UnicodeDecodeError:
                        # Windowsç¼–ç å›é€€
                        encodings = ['cp1252', 'utf-16', 'latin1'] if platform.system() == 'Windows' else ['latin1']
                        content = ""
                        for encoding in encodings:
                            try:
                                with open(file_path, 'r', encoding=encoding) as in_f:
                                    content = in_f.read()
                                break
                            except UnicodeDecodeError:
                                continue
                        else:
                            # ç¼–ç å¤±è´¥ï¼Œä½œä¸ºäºŒè¿›åˆ¶å¤„ç†
                            with open(file_path, 'rb') as in_f:
                                content = base64.b64encode(in_f.read()).decode('ascii')
                                content_parts.append(f"B\n{content}\n")
                                processed_count += 1
                                if show_progress_callback:
                                    show_progress_callback(processed_count, total_files)
                                continue

                    content_parts.append(content)
            content_parts.append("\n")

            processed_count += 1
        except Exception as e:
            content_parts.append(f"\n!{relative_path}\n{str(e)}\n")  # ç®€åŒ–é”™è¯¯æ ‡è®°

        if show_progress_callback:
            show_progress_callback(processed_count, total_files)

    # ä½¿ç”¨è‡ªå®šä¹‰åˆ†éš”ç¬¦è€Œä¸æ˜¯é•¿åˆ†éš”çº¿
    full_content = "".join(content_parts)

    # ä½¿ç”¨é«˜çº§å‹ç¼©ç®—æ³•
    compressed_content = compress_text_advanced(full_content)

    # å°†å‹ç¼©æ ‡è¯†æ·»åŠ åˆ°å‹ç¼©åçš„å†…å®¹å¼€å¤´ï¼Œä½¿ç”¨æ›´çŸ­çš„æ ‡è¯†ç¬¦
    compressed_content = "COMPRESSED\n" + compressed_content
    
    compressed_size = len(compressed_content.encode('utf-8'))  # è·å–å‹ç¼©åå¤§å°
    
    # è®¡ç®—å¹¶æ˜¾ç¤ºå‹ç¼©æ¯”ä¾‹
    if original_size > 0:
        ratio = (1 - compressed_size / original_size) * 100
        print_colored(f"å‹ç¼©æ¯”ä¾‹: åŸå§‹å¤§å° {original_size/1024:.2f} KB â†’ å‹ç¼©å {compressed_size/1024:.2f} KB (å‡å°‘ {ratio:.2f}%) ", 'blue')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(compressed_content)

    # è¿›è¡Œå¿«é€Ÿå®Œæ•´æ€§æ£€æŸ¥
    print_colored("\nâš¡ æ­£åœ¨è¿›è¡Œå¿«é€ŸéªŒè¯...", 'blue')
    is_complete, report = verify_snapshot_integrity_fast(str(output_file), input_path, show_progress_callback)
    display_fast_verification_report(report)

    return output_file


def restore_files_from_txt(txt_path, output_folder):
    """
    ä»åˆå¹¶çš„æ–‡æœ¬æ–‡ä»¶æ¢å¤åŸå§‹æ–‡ä»¶
    ç°åœ¨å¯ä»¥è‡ªåŠ¨åˆ¤æ–­æ˜¯å‹ç¼©æ–‡ä»¶è¿˜æ˜¯æ™®é€šæ–‡æœ¬æ–‡ä»¶
    """
    if not os.path.isfile(txt_path):
        print_colored("é”™è¯¯: è¾“å…¥çš„è·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶!", 'red')
        return
    
    # è¯»å–æ–‡ä»¶å‰å‡ è¡Œåˆ¤æ–­æ–‡ä»¶ç±»å‹
    with open(txt_path, 'r', encoding='utf-8') as f:
        first_lines = [f.readline().strip() for _ in range(3)]
    
    first_line = first_lines[0] if first_lines else ""
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ—§ç‰ˆæœ¬æ ¼å¼
    if first_line == "=== SNAPSHOT_FORMAT: COMPRESSED ===":
        restore_files_from_old_compressed_txt(txt_path, output_folder)
        return
    elif first_line == "=== SNAPSHOT_FORMAT: UNCOMPRESSED ===":
        restore_files_from_old_txt(txt_path, output_folder)
        return
    
    # æ–°ç‰ˆæœ¬æ ¼å¼å¤„ç†
    if first_line == "COMPRESSED":
        restore_files_from_compressed_txt(txt_path, output_folder)
        return  # å‹ç¼©æ¢å¤å®Œæˆåç›´æ¥è¿”å›
    elif first_line == "UNCOMPRESSED":
        # ç§»é™¤æ ¼å¼æ ‡è¯†è¡Œåè°ƒç”¨åŸå§‹æ¢å¤é€»è¾‘
        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read().split('\n', 1)[1]  # è·³è¿‡ç¬¬ä¸€è¡Œ
        
        os.makedirs(output_folder, exist_ok=True)
        
        # åˆ†å‰²æ–‡ä»¶å’Œç›®å½•å— - ä½¿ç”¨æ–°çš„ç®€åŒ–@æ ¼å¼
        parts = []
        current_item = None
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°ï¼ˆ@åè·Ÿè·¯å¾„ï¼Œä¸æ˜¯CSSçš„@è§„åˆ™ï¼‰
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°ï¼ˆ@åè·Ÿè·¯å¾„ï¼Œä¸æ˜¯CSSçš„@è§„åˆ™æˆ–Pythonè£…é¥°å™¨ï¼‰
            if (line.startswith('@') and len(line) > 1 and 
                not line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face')) and
                not line[1:].strip().startswith(('app.route', 'staticmethod', 'classmethod', 'property')) and
                not 'def ' in line and not 'class ' in line):
                if current_item:
                    parts.extend(current_item)
                
                file_path = line[1:]  # ç§»é™¤@å‰ç¼€

                # æ”¶é›†å†…å®¹ç›´åˆ°ä¸‹ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°æˆ–é”™è¯¯æ ‡è®°
                content_lines = []
                i += 1
                while i < len(lines):
                    next_line = lines[i]
                    # å¦‚æœé‡åˆ°æ–°çš„æ–‡ä»¶æ ‡è®°æˆ–é”™è¯¯æ ‡è®°ï¼Œåœæ­¢æ”¶é›†
                    if (next_line.startswith('@') and len(next_line) > 1 and not next_line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face'))) or next_line.startswith('!'):
                        break
                    content_lines.append(next_line)
                    i += 1

                # å¤„ç†å†…å®¹
                if content_lines and content_lines[0] == 'B':
                    # äºŒè¿›åˆ¶æ–‡ä»¶
                    content_block = "[BINARY_FILE_BASE64]\n" + '\n'.join(content_lines[1:])
                elif content_lines and content_lines[0] == '[EMPTY_DIRECTORY]':
                    # ç©ºç›®å½•
                    content_block = "[EMPTY_DIRECTORY]"
                else:
                    # æ–‡æœ¬æ–‡ä»¶ï¼Œä¿æŒæ‰€æœ‰å†…å®¹åŒ…æ‹¬è¡Œå°¾ç©ºç™½
                    # ç§»é™¤æœ€åçš„ç©ºè¡Œï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œå› ä¸ºå†™å…¥æ—¶ä¼šè‡ªåŠ¨æ·»åŠ æ¢è¡Œç¬¦
                    if content_lines and content_lines[-1] == '':
                        content_lines = content_lines[:-1]
                    content_block = '\n'.join(content_lines)

                current_item = ["æ–‡ä»¶", file_path, content_block]
            elif line.startswith('!'):
                # é”™è¯¯æ–‡ä»¶
                if current_item:
                    parts.extend(current_item)
                
                file_path = line[1:]  # ç§»é™¤!å‰ç¼€
                error_content = lines[i+1] if i+1 < len(lines) else ""
                current_item = ["æ–‡ä»¶", file_path, f"ERROR: {error_content}"]
                i += 2

            else:
                # å¦‚æœä¸æ˜¯æ–‡ä»¶æ ‡è®°ï¼Œå¯èƒ½æ˜¯ä¹‹å‰æ–‡ä»¶å†…å®¹çš„ä¸€éƒ¨åˆ†ï¼Œç»§ç»­å¤„ç†
                if current_item:
                    # å°†å½“å‰è¡Œæ·»åŠ åˆ°å½“å‰é¡¹ç›®çš„å†…å®¹ä¸­
                    current_item[2] += '\n' + line
                i += 1
        
        # æ·»åŠ æœ€åä¸€ä¸ªé¡¹ç›®
        if current_item:
            parts.extend(current_item)
        
        # ç¡®ä¿æˆ‘ä»¬æœ‰æ­£ç¡®çš„æ ¼å¼ï¼šç±»å‹ã€è·¯å¾„ã€å†…å®¹å¾ªç¯
        if len(parts) % 3 != 0:
            print_colored("è­¦å‘Š: å¿«ç…§æ–‡ä»¶æ ¼å¼å¯èƒ½å·²æŸåã€‚", 'yellow')
            return

        total_blocks = len(parts) // 3
        if total_blocks == 0:
            print_colored("è­¦å‘Š: æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ–‡ä»¶å—ã€‚", 'yellow')
            return
    else:
        print_colored("é”™è¯¯: æ— æ³•è¯†åˆ«çš„æ–‡ä»¶æ ¼å¼!", 'red')
        return  # æ·»åŠ è¿”å›è¯­å¥ï¼Œé¿å…ç»§ç»­æ‰§è¡Œåé¢çš„ä»£ç 

    # æ¢å¤é€»è¾‘ - å¢å¼ºé”™è¯¯æ¢å¤å’ŒéªŒè¯
    show_progress(0, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # é”™è¯¯è·Ÿè¸ªå’Œç»Ÿè®¡
    success_count = 0
    error_count = 0
    error_details = []
    
    for i in range(0, len(parts), 3):
        if i + 2 >= len(parts):
            break

        block_type = parts[i]        # "æ–‡ä»¶" æˆ– "ç›®å½•"
        file_path = parts[i+1]       # è·¯å¾„
        content_block = parts[i+2]   # å†…å®¹
        
        # æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†Windowsä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§
        sanitized_file_path = sanitize_file_path(file_path)
        # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è¿æ¥
        full_path = str(Path(output_folder) / sanitized_file_path)
        
        try:
            if content_block.strip() == "[EMPTY_DIRECTORY]":
                # åˆ›å»ºç©ºç›®å½•
                os.makedirs(full_path, exist_ok=True)
                success_count += 1

            else:  # æ–‡ä»¶
                # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ï¼Œä½¿ç”¨ Path å¯¹è±¡å¤„ç†
                parent_dir = Path(full_path).parent
                if parent_dir != Path('.'):  # ç¡®ä¿ä¸æ˜¯å½“å‰ç›®å½•
                    parent_dir.mkdir(parents=True, exist_ok=True)

                # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
                if content_block.strip().startswith("[BINARY_FILE_BASE64]"):
                    # äºŒè¿›åˆ¶æ–‡ä»¶
                    base64_content = content_block.split('\n', 1)[1]

                    # å¤‡ä»½å·²å­˜åœ¨çš„æ–‡ä»¶
                    if os.path.exists(full_path):
                        backup_existing_file(full_path)

                    with open(full_path, 'wb') as f:
                        f.write(base64.b64decode(base64_content.encode('ascii')))
                    success_count += 1

                else:
                    # æ–‡æœ¬æ–‡ä»¶ï¼Œä¿æŒåŸå§‹å†…å®¹

                    # å¤‡ä»½å·²å­˜åœ¨çš„æ–‡ä»¶
                    if os.path.exists(full_path):
                        backup_existing_file(full_path)

                    with open(full_path, 'w', encoding='utf-8') as f:
                        f.write(content_block)
                    success_count += 1
                    
        except OSError as e:
            # æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ï¼ˆæƒé™ã€ç£ç›˜ç©ºé—´ç­‰ï¼‰
            error_msg = f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {sanitized_file_path} - {str(e)}"
            # æä¾›æ›´å…·ä½“çš„æƒé™é”™è¯¯ä¿¡æ¯
            if e.errno == 13:  # Permission denied
                error_msg += " (æƒé™è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™æˆ–ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ)"
            elif e.errno == 28:  # No space left on device
                error_msg += " (ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†ç£ç›˜ç©ºé—´)"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except (ValueError, base64.binascii.Error) as e:
            # Base64 è§£ç é”™è¯¯
            error_msg = f"Base64è§£ç é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except UnicodeDecodeError as e:
            # ç¼–ç é”™è¯¯
            error_msg = f"ç¼–ç é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except Exception as e:
            # å…¶ä»–æœªçŸ¥é”™è¯¯
            error_msg = f"æœªçŸ¥é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
        
        show_progress(i // 3 + 1, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # ç”Ÿæˆæ¢å¤æŠ¥å‘Š
    print()
    print_colored(f"æ¢å¤å®Œæˆ: {success_count} ä¸ªæ–‡ä»¶æˆåŠŸ, {error_count} ä¸ªæ–‡ä»¶å¤±è´¥", 
                 'green' if error_count == 0 else 'yellow')
    
    if error_count > 0:
        print_colored("\né”™è¯¯è¯¦æƒ…:", 'yellow')
        for error in error_details[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print_colored(f"  - {error}", 'yellow')
        if error_count > 5:
            print_colored(f"  - ... è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯", 'yellow')
    
    # åˆ›å»ºè¯¦ç»†çš„æ¢å¤æŠ¥å‘Šæ–‡ä»¶
    create_restore_report(success_count, error_count, error_details, output_folder)
    
    print_colored(f"æ–‡ä»¶å·²ä» {txt_path} æ¢å¤åˆ° {output_folder}", 'green')


def compress_text(text):
    """å‹ç¼©æ–‡æœ¬å†…å®¹ï¼Œæ™ºèƒ½é€‰æ‹©æœ€ä½³å‹ç¼©ç­–ç•¥ï¼ŒWindowsä¼˜åŒ–ç‰ˆæœ¬"""
    import zlib
    import bz2

    # é¢„å¤„ç†ï¼šä¿æŒæ‰€æœ‰åŸå§‹å†…å®¹ï¼Œä¸ç§»é™¤ç©ºç™½
    processed_text = text

    original_bytes = processed_text.encode('utf-8')
    original_size = len(original_bytes)

    # Windowsä¼˜åŒ–ï¼šå¯¹äºå°æ–‡ä»¶ä½¿ç”¨æ›´å¿«çš„å‹ç¼©
    size_threshold = 4096 if platform.system() == 'Windows' else 2048

    if original_size < size_threshold:
        print_colored("ä½¿ç”¨å¿«é€Ÿå‹ç¼©æ¨¡å¼ï¼ˆå°æ–‡ä»¶ä¼˜åŒ–ï¼‰...", 'blue')
        try:
            # Windowsä¸Šä½¿ç”¨æ›´å¿«çš„ZLIBå‹ç¼©
            if platform.system() == 'Windows':
                compressed = zlib.compress(original_bytes, level=6)  # å¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœ
                encoded = base64.b85encode(compressed).decode('ascii')
                return f"ZLIB:{encoded}"
            else:
                # å…¶ä»–ç³»ç»Ÿä½¿ç”¨LZMA
                compressed = lzma.compress(original_bytes, preset=6)
                encoded = base64.b85encode(compressed).decode('ascii')
                return encoded
        except:
            return processed_text  # å‹ç¼©å¤±è´¥åˆ™è¿”å›åŸæ–‡

    # å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨å¤šç®—æ³•ä¼˜åŒ–
    print_colored("ä½¿ç”¨å¤šç®—æ³•ä¼˜åŒ–æ¨¡å¼ï¼ˆå¤§æ–‡ä»¶ä¼˜åŒ–ï¼‰...", 'blue')

    # é‡æ–°ç»„ç»‡å†…å®¹ä»¥æé«˜å‹ç¼©ç‡
    reorganized_text = reorganize_content_for_compression(processed_text)
    reorganized_bytes = reorganized_text.encode('utf-8')

    # æµ‹è¯•å‹ç¼©ç®—æ³• - Windowsä¼˜åŒ–é¡ºåº
    results = []

    # Windowsä¼˜å…ˆä½¿ç”¨ZLIBï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
    if platform.system() == 'Windows':
        algorithms = [
            ('ZLIB', lambda data: zlib.compress(data, level=9)),
            ('LZMA', lambda data: lzma.compress(data, format=lzma.FORMAT_XZ, preset=6 | lzma.PRESET_EXTREME)),
            ('BZ2', lambda data: bz2.compress(data, compresslevel=6))  # é™ä½å‹ç¼©çº§åˆ«æé«˜é€Ÿåº¦
        ]
    else:
        algorithms = [
            ('LZMA', lambda data: lzma.compress(data, format=lzma.FORMAT_XZ, preset=9 | lzma.PRESET_EXTREME)),
            ('BZ2', lambda data: bz2.compress(data, compresslevel=9)),
            ('ZLIB', lambda data: zlib.compress(data, level=9))
        ]

    for method, compress_func in algorithms:
        try:
            compressed = compress_func(reorganized_bytes)
            encoded = base64.b85encode(compressed).decode('ascii')
            results.append((method, encoded, len(encoded)))
            print_colored(f"  {method}: {len(encoded)} å­—ç¬¦", 'blue')
        except Exception as e:
            print_colored(f"  {method}å¤±è´¥: {e}", 'yellow')

    if not results:
        print_colored("è­¦å‘Š: æ‰€æœ‰å‹ç¼©ç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬", 'yellow')
        return f"RAW:{processed_text}"

    # é€‰æ‹©æœ€ä½³ç»“æœ
    best_method, best_compressed, best_size = min(results, key=lambda x: x[2])
    print_colored(f"é€‰æ‹©æœ€ä½³ç®—æ³•: {best_method} (å‹ç¼©å {best_size} å­—ç¬¦)", 'green')

    return f"{best_method}:{best_compressed}"


def restore_files_from_compressed_txt(txt_path, output_folder):
    """ä»å‹ç¼©çš„æ–‡æœ¬æ–‡ä»¶æ¢å¤åŸå§‹æ–‡ä»¶"""
    if not os.path.isfile(txt_path):
        print_colored("é”™è¯¯: è¾“å…¥çš„è·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶!", 'red')
        return

    # è¯»å–å‹ç¼©å†…å®¹
    print("æ­£åœ¨è¯»å–å¹¶è§£å‹ç¼©æ–‡ä»¶...")
    with open(txt_path, 'r', encoding='utf-8') as f:
        first_line = f.readline().strip()
        if first_line != "COMPRESSED":
            print_colored("é”™è¯¯: æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®!", 'red')
            return
        # è¯»å–å‰©ä½™å†…å®¹
        compressed_content = f.read()
    
    try:
        # è§£æå‹ç¼©æ ¼å¼å’Œæ•°æ®
        if ':' in compressed_content:
            method, encoded_data = compressed_content.split(':', 1)
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨LZMA
            method = 'LZMA'
            encoded_data = compressed_content
        
        # å…ˆè§£ç base85
        compressed = base64.b85decode(encoded_data.encode('ascii'))
        
        # æ ¹æ®å‹ç¼©æ–¹æ³•è§£å‹
        if method == 'LZMA':
            decompressed_content = lzma.decompress(compressed).decode('utf-8')
        elif method == 'BZ2':
            import bz2
            decompressed_content = bz2.decompress(compressed).decode('utf-8')
        elif method == 'ZLIB':
            import zlib
            decompressed_content = zlib.decompress(compressed).decode('utf-8')
        elif method == 'RAW':
            # åŸå§‹æ–‡æœ¬ï¼Œæ— éœ€è§£å‹
            decompressed_content = encoded_data
        # æ–°å¢é«˜çº§å‹ç¼©æ ¼å¼æ”¯æŒ
        elif method == 'LZMA_EXTREME':
            decompressed_content = lzma.decompress(compressed).decode('utf-8')
        elif method == 'ZLIB_ULTRA':
            import zlib
            decompressed_content = zlib.decompress(compressed).decode('utf-8')
        elif method == 'BZ2_MAX':
            import bz2
            decompressed_content = bz2.decompress(compressed).decode('utf-8')
        else:
            print_colored(f"é”™è¯¯: ä¸æ”¯æŒçš„å‹ç¼©æ–¹æ³• {method}", 'red')
            return
        
        # æ˜¾ç¤ºè§£å‹æ¯”ä¾‹å’Œä½¿ç”¨çš„ç®—æ³•
        compressed_size = len(compressed_content.encode('utf-8'))
        original_size = len(decompressed_content.encode('utf-8'))
        if compressed_size > 0:
            ratio = (original_size / compressed_size) * 100
            print_colored(f"è§£å‹æ¯”ä¾‹: å‹ç¼©æ–‡ä»¶ {compressed_size/1024:.2f} KB â†’ è§£å‹å {original_size/1024:.2f} KB (åŸå§‹å¤§å°çš„ {ratio:.2f}%) [ç®—æ³•: {method}]", 'blue')
            
    except Exception as e:
        print_colored(f"è§£å‹ç¼©å¤±è´¥: {str(e)}", 'red')
        return
    
    # æ¢å¤æ–‡ä»¶å†…å®¹
    os.makedirs(output_folder, exist_ok=True)
    
    # åˆ†å‰²æ–‡ä»¶å’Œç›®å½•å— - ä½¿ç”¨æ–°çš„ç®€åŒ–@æ ¼å¼
    parts = []
    current_item = None
    lines = decompressed_content.split('\n')
    
    i = 0
    while i < len(lines):
        line = lines[i]
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°ï¼ˆ@åè·Ÿè·¯å¾„ï¼Œä¸æ˜¯CSSçš„@è§„åˆ™æˆ–Pythonè£…é¥°å™¨ï¼‰
        if (line.startswith('@') and len(line) > 1 and 
            not line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face')) and
            not line[1:].strip().startswith(('app.route', 'staticmethod', 'classmethod', 'property')) and
            not 'def ' in line and not 'class ' in line):
            if current_item:
                parts.extend(current_item)
            
            file_path = line[1:]  # ç§»é™¤@å‰ç¼€
            
            # æ”¶é›†å†…å®¹ç›´åˆ°ä¸‹ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°æˆ–é”™è¯¯æ ‡è®°
            content_lines = []
            i += 1
            while i < len(lines):
                next_line = lines[i]
                # å¦‚æœé‡åˆ°æ–°çš„æ–‡ä»¶æ ‡è®°æˆ–é”™è¯¯æ ‡è®°ï¼Œåœæ­¢æ”¶é›†
                if (next_line.startswith('@') and len(next_line) > 1 and not next_line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face'))) or next_line.startswith('!'):
                    break
                content_lines.append(next_line)
                i += 1
            
            # å¤„ç†å†…å®¹
            if content_lines and content_lines[0] == 'B':
                # äºŒè¿›åˆ¶æ–‡ä»¶
                content = "[BINARY_FILE_BASE64]\n" + '\n'.join(content_lines[1:])
            elif content_lines and content_lines[0] == '[EMPTY_DIRECTORY]':
                # ç©ºç›®å½•
                content = "[EMPTY_DIRECTORY]"
            else:
                # æ–‡æœ¬æ–‡ä»¶ï¼Œç§»é™¤æœ€åçš„ç©ºè¡Œï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if content_lines and content_lines[-1] == '':
                    content_lines = content_lines[:-1]
                content = '\n'.join(content_lines)
            
            current_item = ["æ–‡ä»¶", file_path, content]
            continue
        elif line.startswith('!'):
            # é”™è¯¯æ–‡ä»¶
            if current_item:
                parts.extend(current_item)
            
            file_path = line[1:]  # ç§»é™¤!å‰ç¼€
            error_content = lines[i+1] if i+1 < len(lines) else ""
            current_item = ["æ–‡ä»¶", file_path, f"ERROR: {error_content}"]
            i += 2

        else:
            # å¦‚æœä¸æ˜¯æ–‡ä»¶æ ‡è®°ï¼Œå¯èƒ½æ˜¯ä¹‹å‰æ–‡ä»¶å†…å®¹çš„ä¸€éƒ¨åˆ†ï¼Œç»§ç»­å¤„ç†
            if current_item:
                # å°†å½“å‰è¡Œæ·»åŠ åˆ°å½“å‰é¡¹ç›®çš„å†…å®¹ä¸­
                current_item[2] += '\n' + line
            i += 1
    
    # æ·»åŠ æœ€åä¸€ä¸ªé¡¹ç›®
    if current_item:
        parts.extend(current_item)
    
    # ç¡®ä¿æˆ‘ä»¬æœ‰æ­£ç¡®çš„æ ¼å¼ï¼šç±»å‹ã€è·¯å¾„ã€å†…å®¹å¾ªç¯
    if len(parts) % 3 != 0:
        print_colored("è­¦å‘Š: å¿«ç…§æ–‡ä»¶æ ¼å¼å¯èƒ½å·²æŸåã€‚", 'yellow')
        return
        
    total_blocks = len(parts) // 3
    if total_blocks == 0:
        print_colored("è­¦å‘Š: æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ–‡ä»¶å—ã€‚", 'yellow')
        return

    # æ¢å¤é€»è¾‘ - å¢å¼ºé”™è¯¯æ¢å¤å’ŒéªŒè¯
    show_progress(0, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # é”™è¯¯è·Ÿè¸ªå’Œç»Ÿè®¡
    success_count = 0
    error_count = 0
    error_details = []
    
    for i in range(0, len(parts), 3):
        if i + 2 >= len(parts):
            break

        block_type = parts[i]        # "æ–‡ä»¶" æˆ– "ç›®å½•"
        file_path = parts[i+1]       # è·¯å¾„
        content_block = parts[i+2]   # å†…å®¹
        
        # æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†Windowsä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§
        sanitized_file_path = sanitize_file_path(file_path)
        # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è¿æ¥
        full_path = str(Path(output_folder) / sanitized_file_path)
        
        try:
            if content_block.strip() == "[EMPTY_DIRECTORY]":
                # åˆ›å»ºç©ºç›®å½•
                os.makedirs(full_path, exist_ok=True)
                success_count += 1

            else:  # æ™®é€šæ–‡ä»¶
                # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ï¼Œä½¿ç”¨ Path å¯¹è±¡å¤„ç†
                parent_dir = Path(full_path).parent
                if parent_dir != Path('.'):  # ç¡®ä¿ä¸æ˜¯å½“å‰ç›®å½•
                    parent_dir.mkdir(parents=True, exist_ok=True)

                # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
                if content_block.strip().startswith("[BINARY_FILE_BASE64]"):
                    # äºŒè¿›åˆ¶æ–‡ä»¶
                    base64_content = content_block.split('\n', 1)[1]
                    with open(full_path, 'wb') as f:
                        f.write(base64.b64decode(base64_content.encode('ascii')))
                    success_count += 1

                else:
                    # æ–‡æœ¬æ–‡ä»¶ï¼Œä¿æŒåŸå§‹å†…å®¹
                    with open(full_path, 'w', encoding='utf-8') as f:
                        f.write(content_block)
                    success_count += 1
                    
        except OSError as e:
            # æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ï¼ˆæƒé™ã€ç£ç›˜ç©ºé—´ç­‰ï¼‰
            error_msg = f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except (ValueError, base64.binascii.Error) as e:
            # Base64 è§£ç é”™è¯¯
            error_msg = f"Base64è§£ç é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except UnicodeDecodeError as e:
            # ç¼–ç é”™è¯¯
            error_msg = f"ç¼–ç é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except Exception as e:
            # å…¶ä»–æœªçŸ¥é”™è¯¯
            error_msg = f"æœªçŸ¥é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
        
        show_progress(i // 3 + 1, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # ç”Ÿæˆæ¢å¤æŠ¥å‘Š
    print()
    print_colored(f"æ¢å¤å®Œæˆ: {success_count} ä¸ªæ–‡ä»¶æˆåŠŸ, {error_count} ä¸ªæ–‡ä»¶å¤±è´¥", 
                 'green' if error_count == 0 else 'yellow')
    
    if error_count > 0:
        print_colored("\né”™è¯¯è¯¦æƒ…:", 'yellow')
        for error in error_details[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print_colored(f"  - {error}", 'yellow')
        if error_count > 5:
            print_colored(f"  - ... è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯", 'yellow')
    
    print_colored(f"æ–‡ä»¶å·²ä» {txt_path} æ¢å¤åˆ° {output_folder}", 'green')


def get_unique_filepath(filepath):
    """å¦‚æœæ–‡ä»¶è·¯å¾„å·²å­˜åœ¨ï¼Œåˆ™åœ¨æ‰©å±•åå‰é™„åŠ '_<æ•°å­—>'ä»¥åˆ›å»ºå”¯ä¸€è·¯å¾„"""
    if not os.path.exists(filepath):
        return filepath
    
    filepath = Path(filepath)
    directory = filepath.parent
    name = filepath.stem
    extension = filepath.suffix
    
    counter = 1
    while True:
        new_name = f"{name}_{counter}{extension}"
        new_filepath = directory / new_name
        if not new_filepath.exists():
            return str(new_filepath)  # è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯Pathå¯¹è±¡
        counter += 1


def backup_existing_file(file_path):
    """å¤‡ä»½å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œé¿å…è¦†ç›–"""
    if not os.path.exists(file_path):
        return True  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½
    
    try:
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        backup_dir = os.path.join(os.path.dirname(file_path), ".snapshot_backups")
        os.makedirs(backup_dir, exist_ok=True)
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.basename(file_path)
        backup_path = os.path.join(backup_dir, f"{filename}.backup_{timestamp}")
        
        # å¤åˆ¶æ–‡ä»¶åˆ°å¤‡ä»½ä½ç½®
        import shutil
        shutil.copy2(file_path, backup_path)
        
        print_colored(f"å·²å¤‡ä»½åŸæ–‡ä»¶: {file_path} â†’ {backup_path}", 'blue')
        return True
        
    except Exception as e:
        print_colored(f"è­¦å‘Š: å¤‡ä»½æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}", 'yellow')
        return False


def verify_snapshot_integrity_fast(snapshot_path, original_path, show_progress_callback=None):
    """
    å¿«é€ŸéªŒè¯å¿«ç…§æ–‡ä»¶å®Œæ•´æ€§ - ä¼˜åŒ–ç‰ˆæœ¬
    é€šè¿‡æ–‡ä»¶å…ƒæ•°æ®å’ŒæŠ½æ ·æ£€æŸ¥æ¥æé«˜éªŒè¯é€Ÿåº¦

    :param snapshot_path: å¿«ç…§æ–‡ä»¶è·¯å¾„
    :param original_path: åŸå§‹æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„
    :param show_progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    :return: (is_complete, verification_report)
    """
    if not os.path.exists(snapshot_path):
        return False, {"error": "å¿«ç…§æ–‡ä»¶ä¸å­˜åœ¨"}

    if not os.path.exists(original_path):
        return False, {"error": "åŸå§‹è·¯å¾„ä¸å­˜åœ¨"}

    print_colored("ğŸ” å¼€å§‹å¿«é€ŸéªŒè¯å¿«ç…§å®Œæ•´æ€§...", 'blue')

    # Windowsä¼˜åŒ–ï¼šé€‰æ‹©åˆé€‚çš„äºŒè¿›åˆ¶æ£€æµ‹å‡½æ•°
    if platform.system() == 'Windows':
        binary_check_func = is_binary_file_windows_optimized
    else:
        binary_check_func = is_binary_file

    # æ”¶é›†åŸå§‹æ–‡ä»¶åŸºæœ¬ä¿¡æ¯ï¼ˆä¸è®¡ç®—å“ˆå¸Œï¼‰
    original_files = {}
    total_original_size = 0

    if os.path.isfile(original_path):
        # å•ä¸ªæ–‡ä»¶
        filename = os.path.basename(original_path)
        file_size = os.path.getsize(original_path)
        original_files[filename] = {
            'size': file_size,
            'type': 'binary' if binary_check_func(original_path) else 'text',
            'mtime': os.path.getmtime(original_path)  # ä¿®æ”¹æ—¶é—´
        }
        total_original_size = file_size
    else:
        # æ–‡ä»¶å¤¹
        base_path = os.path.normpath(original_path)
        for root, dirs, files in os.walk(original_path):
            # å¤„ç†æ–‡ä»¶
            for file in files:
                file_path = get_safe_path(os.path.join(root, file))
                relative_path = os.path.relpath(file_path, start=base_path).replace(os.sep, '/')
                file_size = os.path.getsize(file_path)
                original_files[relative_path] = {
                    'size': file_size,
                    'type': 'binary' if binary_check_func(file_path) else 'text',
                    'mtime': os.path.getmtime(file_path)
                }
                total_original_size += file_size

            # å¤„ç†ç©ºç›®å½•
            for dir_name in dirs:
                dir_path = get_safe_path(os.path.join(root, dir_name))
                if not os.listdir(dir_path):
                    relative_path = os.path.relpath(dir_path, start=base_path).replace(os.sep, '/')
                    original_files[relative_path] = {
                        'size': 0,
                        'type': 'directory',
                        'mtime': os.path.getmtime(dir_path)
                    }

    # å¿«é€Ÿè§£æå¿«ç…§æ–‡ä»¶ï¼ˆåªè§£æç»“æ„ï¼Œä¸è§£ç å†…å®¹ï¼‰
    snapshot_files = {}
    try:
        with open(snapshot_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()

            if first_line == "COMPRESSED":
                # å‹ç¼©æ ¼å¼ - åªæ£€æŸ¥æ˜¯å¦èƒ½æˆåŠŸè§£å‹ï¼ˆä¸å®Œå…¨è§£å‹ï¼‰
                compressed_content = f.read()
                if ':' in compressed_content:
                    method, encoded_data = compressed_content.split(':', 1)
                else:
                    method = 'LZMA'
                    encoded_data = compressed_content

                try:
                    # Windowsä¼˜åŒ–ï¼šåªè¿›è¡ŒåŸºæœ¬çš„æ ¼å¼éªŒè¯ï¼Œé¿å…å®é™…è§£å‹ç¼©
                    compressed = base64.b85decode(encoded_data.encode('ascii'))

                    # ç®€åŒ–çš„å‹ç¼©æ ¼å¼éªŒè¯ï¼ˆä¸å®é™…è§£å‹ç¼©ï¼‰
                    if method == 'LZMA':
                        # æ£€æŸ¥LZMAæ–‡ä»¶å¤´
                        if len(compressed) >= 6:
                            # LZMA/XZæ–‡ä»¶å¤´: 0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00
                            lzma_header = compressed[:6]
                            if lzma_header.startswith(b'\xFD7zXZ') or lzma_header.startswith(b'\x5D\x00\x00'):
                                pass  # æœ‰æ•ˆçš„LZMAæ ¼å¼
                            else:
                                raise ValueError("ä¸æ˜¯æœ‰æ•ˆçš„LZMAæ ¼å¼")
                    elif method == 'BZ2':
                        # æ£€æŸ¥BZ2æ–‡ä»¶å¤´: 'BZ'
                        if len(compressed) >= 2 and compressed[:2] == b'BZ':
                            pass  # æœ‰æ•ˆçš„BZ2æ ¼å¼
                        else:
                            raise ValueError("ä¸æ˜¯æœ‰æ•ˆçš„BZ2æ ¼å¼")
                    elif method == 'ZLIB':
                        # æ£€æŸ¥ZLIBæ–‡ä»¶å¤´
                        if len(compressed) >= 2:
                            # ZLIBæ ¼å¼æ£€æŸ¥
                            first_byte = compressed[0]
                            second_byte = compressed[1]
                            if (first_byte * 256 + second_byte) % 31 == 0:
                                pass  # æœ‰æ•ˆçš„ZLIBæ ¼å¼
                            else:
                                raise ValueError("ä¸æ˜¯æœ‰æ•ˆçš„ZLIBæ ¼å¼")
                    elif method == 'RAW':
                        pass  # RAWæ ¼å¼æ— éœ€éªŒè¯

                    # ä¼°ç®—æ–‡ä»¶æ•°é‡ï¼ˆåŸºäºå‹ç¼©å†…å®¹ä¸­çš„@æ ‡è®°æ•°é‡ï¼‰
                    estimated_files = encoded_data.count('@')
                    snapshot_files['_metadata'] = {
                        'format': 'compressed',
                        'method': method,
                        'estimated_files': estimated_files,
                        'compressed_size': len(compressed)
                    }

                except Exception as e:
                    # å¦‚æœå‹ç¼©éªŒè¯å¤±è´¥ï¼Œä»ç„¶ç»§ç»­ï¼Œä½†æ ‡è®°ä¸ºå¯èƒ½æœ‰é—®é¢˜
                    print_colored(f"âš ï¸  å‹ç¼©æ ¼å¼éªŒè¯è­¦å‘Š: {str(e)}", 'yellow')
                    snapshot_files['_metadata'] = {
                        'format': 'compressed',
                        'method': method,
                        'estimated_files': encoded_data.count('@'),
                        'compressed_size': len(base64.b85decode(encoded_data.encode('ascii'))) if encoded_data else 0,
                        'validation_warning': str(e)
                    }

            elif first_line == "UNCOMPRESSED":
                # æœªå‹ç¼©æ ¼å¼ - å¿«é€Ÿç»Ÿè®¡æ–‡ä»¶æ ‡è®°
                content = f.read()

                # å¿«é€Ÿç»Ÿè®¡@å’Œ!æ ‡è®°
                file_markers = content.count('\n@')
                error_markers = content.count('\n!')
                directory_markers = content.count('[EMPTY_DIRECTORY]')
                binary_markers = content.count('\nB\n')

                snapshot_files['_metadata'] = {
                    'format': 'uncompressed',
                    'total_markers': file_markers,
                    'error_markers': error_markers,
                    'directory_markers': directory_markers,
                    'binary_markers': binary_markers,
                    'content_size': len(content)
                }

            else:
                return False, {"error": "æ— æ³•è¯†åˆ«çš„å¿«ç…§æ ¼å¼"}

    except Exception as e:
        return False, {"error": f"è§£æå¿«ç…§æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

    # å¿«é€ŸéªŒè¯æŠ¥å‘Š
    verification_report = {
        'total_original_files': len(original_files),
        'total_original_size': total_original_size,
        'verification_type': 'fast',
        'snapshot_metadata': snapshot_files.get('_metadata', {}),
        'checks_performed': [],
        'warnings': [],
        'is_complete': True  # é»˜è®¤å®Œæ•´ï¼Œé™¤éå‘ç°æ˜æ˜¾é—®é¢˜
    }

    # æ‰§è¡Œå¿«é€Ÿæ£€æŸ¥
    checks_performed = []

    # 1. æ–‡ä»¶æ•°é‡æ£€æŸ¥
    if snapshot_files['_metadata']['format'] == 'uncompressed':
        estimated_files = snapshot_files['_metadata']['total_markers']
        if abs(estimated_files - len(original_files)) > len(original_files) * 0.1:  # å·®å¼‚è¶…è¿‡10%
            verification_report['warnings'].append(f"æ–‡ä»¶æ•°é‡å·®å¼‚è¾ƒå¤§: åŸå§‹{len(original_files)}ä¸ªï¼Œå¿«ç…§çº¦{estimated_files}ä¸ª")
            verification_report['is_complete'] = False
        checks_performed.append(f"æ–‡ä»¶æ•°é‡æ£€æŸ¥: åŸå§‹{len(original_files)}ä¸ªï¼Œå¿«ç…§çº¦{estimated_files}ä¸ª")

    # 2. å¿«ç…§æ–‡ä»¶å¤§å°åˆç†æ€§æ£€æŸ¥
    snapshot_size = os.path.getsize(snapshot_path)
    if snapshot_files['_metadata']['format'] == 'compressed':
        # å‹ç¼©æ–‡ä»¶å¤§å°åº”è¯¥å°äºåŸå§‹å¤§å°
        if snapshot_size > total_original_size:
            verification_report['warnings'].append("å‹ç¼©å¿«ç…§æ–‡ä»¶æ¯”åŸå§‹æ–‡ä»¶è¿˜å¤§ï¼Œå¯èƒ½æœ‰é—®é¢˜")
            verification_report['is_complete'] = False
        compression_ratio = (1 - snapshot_size / total_original_size) * 100 if total_original_size > 0 else 0
        checks_performed.append(f"å‹ç¼©æ¯”æ£€æŸ¥: {compression_ratio:.1f}% (åŸå§‹{total_original_size/1024:.1f}KB -> å‹ç¼©{snapshot_size/1024:.1f}KB)")
    else:
        # æœªå‹ç¼©æ–‡ä»¶å¤§å°åº”è¯¥æ¥è¿‘åŸå§‹å¤§å°
        size_ratio = snapshot_size / total_original_size if total_original_size > 0 else 0
        if size_ratio < 0.8 or size_ratio > 2.0:  # å¤§å°å·®å¼‚è¿‡å¤§
            verification_report['warnings'].append(f"æœªå‹ç¼©å¿«ç…§å¤§å°å¼‚å¸¸: æ¯”ç‡{size_ratio:.2f}")
            verification_report['is_complete'] = False
        checks_performed.append(f"å¤§å°åˆç†æ€§æ£€æŸ¥: æ¯”ç‡{size_ratio:.2f} (å¿«ç…§{snapshot_size/1024:.1f}KB)")

    # 3. é”™è¯¯æ ‡è®°æ£€æŸ¥
    if 'error_markers' in snapshot_files['_metadata'] and snapshot_files['_metadata']['error_markers'] > 0:
        verification_report['warnings'].append(f"å‘ç°{snapshot_files['_metadata']['error_markers']}ä¸ªé”™è¯¯æ–‡ä»¶æ ‡è®°")
        verification_report['is_complete'] = False
        checks_performed.append(f"é”™è¯¯æ ‡è®°æ£€æŸ¥: å‘ç°{snapshot_files['_metadata']['error_markers']}ä¸ªé”™è¯¯")
    else:
        checks_performed.append("é”™è¯¯æ ‡è®°æ£€æŸ¥: æœªå‘ç°é”™è¯¯æ ‡è®°")

    # 4. äºŒè¿›åˆ¶æ–‡ä»¶æ¯”ä¾‹æ£€æŸ¥
    original_binary_count = len([f for f in original_files.values() if f['type'] == 'binary'])
    if 'binary_markers' in snapshot_files['_metadata']:
        snapshot_binary_count = snapshot_files['_metadata']['binary_markers']
        if abs(original_binary_count - snapshot_binary_count) > 2:  # å…è®¸å°å¹…å·®å¼‚
            verification_report['warnings'].append(f"äºŒè¿›åˆ¶æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: åŸå§‹{original_binary_count}ä¸ªï¼Œå¿«ç…§{snapshot_binary_count}ä¸ª")
        checks_performed.append(f"äºŒè¿›åˆ¶æ–‡ä»¶æ£€æŸ¥: åŸå§‹{original_binary_count}ä¸ªï¼Œå¿«ç…§{snapshot_binary_count}ä¸ª")

    verification_report['checks_performed'] = checks_performed

    # è®¡ç®—æˆåŠŸç‡ï¼ˆåŸºäºæ£€æŸ¥é¡¹ç›®ï¼‰
    warning_count = len(verification_report['warnings'])
    check_count = len(checks_performed)
    success_rate = ((check_count - warning_count) / check_count * 100) if check_count > 0 else 100
    verification_report['success_rate'] = success_rate

    return verification_report['is_complete'], verification_report


def display_fast_verification_report(report):
    """æ˜¾ç¤ºå¿«é€ŸéªŒè¯æŠ¥å‘Š - Windowsä¼˜åŒ–ç‰ˆæœ¬"""
    print_colored("\n" + "="*60, 'cyan')
    print_colored("âš¡ å¿«é€ŸéªŒè¯æŠ¥å‘Š", 'cyan')
    print_colored("="*60, 'cyan')

    # æ€»ä½“ç»Ÿè®¡
    print_colored(f"ğŸ“ åŸå§‹æ–‡ä»¶æ€»æ•°: {report['total_original_files']}", 'blue')
    print_colored(f"ğŸ’¾ åŸå§‹æ•°æ®å¤§å°: {report['total_original_size']/1024:.2f} KB", 'blue')
    print_colored(f"âš¡ éªŒè¯ç±»å‹: å¿«é€ŸéªŒè¯", 'blue')
    print_colored(f"ğŸ“Š æ£€æŸ¥æˆåŠŸç‡: {report['success_rate']:.1f}%", 'green' if report['success_rate'] >= 90 else 'yellow')

    # å¿«ç…§ä¿¡æ¯
    metadata = report.get('snapshot_metadata', {})
    if metadata:
        print_colored(f"\nğŸ“„ å¿«ç…§æ ¼å¼: {metadata.get('format', 'æœªçŸ¥')}", 'blue')
        if metadata.get('format') == 'compressed':
            print_colored(f"ğŸ—œï¸  å‹ç¼©æ–¹æ³•: {metadata.get('method', 'æœªçŸ¥')}", 'blue')
            print_colored(f"ğŸ“¦ å‹ç¼©å¤§å°: {metadata.get('compressed_size', 0)/1024:.2f} KB", 'blue')

        if 'estimated_files' in metadata:
            print_colored(f"ğŸ“Š ä¼°ç®—æ–‡ä»¶æ•°: {metadata['estimated_files']}", 'blue')

        # æ˜¾ç¤ºéªŒè¯è­¦å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
        if 'validation_warning' in metadata:
            print_colored(f"âš ï¸  éªŒè¯è­¦å‘Š: {metadata['validation_warning']}", 'yellow')

    # æ£€æŸ¥é¡¹ç›®
    if report.get('checks_performed'):
        print_colored(f"\nâœ… æ‰§è¡Œçš„æ£€æŸ¥:", 'green')
        for check in report['checks_performed']:
            print_colored(f"  - {check}", 'blue')

    # è­¦å‘Šä¿¡æ¯
    if report.get('warnings'):
        print_colored(f"\nâš ï¸  å‘ç°çš„é—®é¢˜ ({len(report['warnings'])} ä¸ª):", 'yellow')
        for warning in report['warnings']:
            print_colored(f"  - {warning}", 'yellow')

    # ç»“è®º
    print_colored("\n" + "="*60, 'cyan')
    if report['is_complete']:
        print_colored("ğŸ‰ å¿«é€ŸéªŒè¯é€šè¿‡ï¼å¿«ç…§çœ‹èµ·æ¥æ˜¯å®Œæ•´çš„ã€‚", 'green')
        print_colored("ğŸ’¡ å¦‚éœ€è¯¦ç»†éªŒè¯ï¼Œè¯·ä½¿ç”¨å®Œæ•´éªŒè¯åŠŸèƒ½ã€‚", 'blue')
    else:
        print_colored("âš ï¸  å¿«é€ŸéªŒè¯å‘ç°é—®é¢˜ï¼Œå»ºè®®è¿›è¡Œå®Œæ•´éªŒè¯ï¼", 'red')

    # Windowsæ€§èƒ½æç¤º
    if platform.system() == 'Windows':
        print_colored("ğŸ’¡ Windowsç”¨æˆ·æç¤º: å¦‚éªŒè¯è¾ƒæ…¢ï¼Œå»ºè®®æš‚æ—¶å…³é—­å®æ—¶æ€æ¯’è½¯ä»¶", 'blue')

    print_colored("="*60, 'cyan')


def verify_snapshot_integrity(snapshot_path, original_path, show_progress_callback=None):
    """
    éªŒè¯å¿«ç…§æ–‡ä»¶æ˜¯å¦å®Œæ•´åŒ…å«äº†æ‰€æœ‰åŸå§‹æ–‡ä»¶å†…å®¹

    :param snapshot_path: å¿«ç…§æ–‡ä»¶è·¯å¾„
    :param original_path: åŸå§‹æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„
    :param show_progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    :return: (is_complete, verification_report)
    """
    if not os.path.exists(snapshot_path):
        return False, {"error": "å¿«ç…§æ–‡ä»¶ä¸å­˜åœ¨"}

    if not os.path.exists(original_path):
        return False, {"error": "åŸå§‹è·¯å¾„ä¸å­˜åœ¨"}

    print_colored("ğŸ” å¼€å§‹éªŒè¯å¿«ç…§å®Œæ•´æ€§...", 'blue')

    # æ”¶é›†åŸå§‹æ–‡ä»¶ä¿¡æ¯
    original_files = {}
    total_original_size = 0

    if os.path.isfile(original_path):
        # å•ä¸ªæ–‡ä»¶
        filename = os.path.basename(original_path)
        file_size = os.path.getsize(original_path)
        file_hash = calculate_file_checksum(original_path)
        original_files[filename] = {
            'size': file_size,
            'hash': file_hash,
            'type': 'binary' if is_binary_file(original_path) else 'text'
        }
        total_original_size = file_size
    else:
        # æ–‡ä»¶å¤¹
        base_path = os.path.normpath(original_path)
        for root, dirs, files in os.walk(original_path):
            # å¤„ç†æ–‡ä»¶
            for file in files:
                file_path = get_safe_path(os.path.join(root, file))
                relative_path = os.path.relpath(file_path, start=base_path).replace(os.sep, '/')
                file_size = os.path.getsize(file_path)
                file_hash = calculate_file_checksum(file_path)
                original_files[relative_path] = {
                    'size': file_size,
                    'hash': file_hash,
                    'type': 'binary' if is_binary_file(file_path) else 'text'
                }
                total_original_size += file_size

            # å¤„ç†ç©ºç›®å½•
            for dir_name in dirs:
                dir_path = get_safe_path(os.path.join(root, dir_name))
                if not os.listdir(dir_path):
                    relative_path = os.path.relpath(dir_path, start=base_path).replace(os.sep, '/')
                    original_files[relative_path] = {
                        'size': 0,
                        'hash': None,
                        'type': 'directory'
                    }

    # è§£æå¿«ç…§æ–‡ä»¶å†…å®¹
    snapshot_files = {}
    try:
        with open(snapshot_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()

            if first_line == "COMPRESSED":
                # å‹ç¼©æ ¼å¼
                compressed_content = f.read()
                if ':' in compressed_content:
                    method, encoded_data = compressed_content.split(':', 1)
                else:
                    method = 'LZMA'
                    encoded_data = compressed_content

                compressed = base64.b85decode(encoded_data.encode('ascii'))

                if method == 'LZMA':
                    decompressed_content = lzma.decompress(compressed).decode('utf-8')
                elif method == 'BZ2':
                    import bz2
                    decompressed_content = bz2.decompress(compressed).decode('utf-8')
                elif method == 'ZLIB':
                    import zlib
                    decompressed_content = zlib.decompress(compressed).decode('utf-8')
                elif method == 'RAW':
                    decompressed_content = encoded_data
                else:
                    return False, {"error": f"ä¸æ”¯æŒçš„å‹ç¼©æ–¹æ³•: {method}"}

                content = decompressed_content

            elif first_line == "UNCOMPRESSED":
                # æœªå‹ç¼©æ ¼å¼
                content = f.read()
            else:
                return False, {"error": "æ— æ³•è¯†åˆ«çš„å¿«ç…§æ ¼å¼"}

        # è§£ææ–‡ä»¶å†…å®¹
        lines = content.split('\n')
        i = 0
        while i < len(lines):
            line = lines[i]

            if (line.startswith('@') and len(line) > 1 and
                not line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face')) and
                not line[1:].strip().startswith(('app.route', 'staticmethod', 'classmethod', 'property')) and
                not 'def ' in line and not 'class ' in line):

                file_path = line[1:]  # ç§»é™¤@å‰ç¼€

                # æ”¶é›†å†…å®¹
                content_lines = []
                i += 1
                while i < len(lines):
                    next_line = lines[i]
                    if (next_line.startswith('@') and len(next_line) > 1 and
                        not next_line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face'))) or next_line.startswith('!'):
                        break
                    content_lines.append(next_line)
                    i += 1

                # åˆ†æå†…å®¹ç±»å‹å’Œå¤§å°
                if content_lines and content_lines[0] == 'B':
                    # äºŒè¿›åˆ¶æ–‡ä»¶
                    base64_content = '\n'.join(content_lines[1:])
                    try:
                        decoded_content = base64.b64decode(base64_content.encode('ascii'))
                        snapshot_files[file_path] = {
                            'size': len(decoded_content),
                            'hash': hashlib.sha256(decoded_content).hexdigest(),
                            'type': 'binary',
                            'status': 'found'
                        }
                    except Exception as e:
                        snapshot_files[file_path] = {
                            'error': f"Base64è§£ç å¤±è´¥: {str(e)}",
                            'type': 'binary',
                            'status': 'error'
                        }
                elif content_lines and content_lines[0] == '[EMPTY_DIRECTORY]':
                    # ç©ºç›®å½•
                    snapshot_files[file_path] = {
                        'size': 0,
                        'hash': None,
                        'type': 'directory',
                        'status': 'found'
                    }
                else:
                    # æ–‡æœ¬æ–‡ä»¶
                    if content_lines and content_lines[-1] == '':
                        content_lines = content_lines[:-1]
                    text_content = '\n'.join(content_lines)
                    text_bytes = text_content.encode('utf-8')
                    snapshot_files[file_path] = {
                        'size': len(text_bytes),
                        'hash': hashlib.sha256(text_bytes).hexdigest(),
                        'type': 'text',
                        'status': 'found'
                    }
                continue
            elif line.startswith('!'):
                # é”™è¯¯æ–‡ä»¶
                file_path = line[1:]
                error_content = lines[i+1] if i+1 < len(lines) else ""
                snapshot_files[file_path] = {
                    'error': error_content,
                    'status': 'error'
                }
                i += 2
                continue
            i += 1

    except Exception as e:
        return False, {"error": f"è§£æå¿«ç…§æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}

    # æ¯”è¾ƒåŸå§‹æ–‡ä»¶å’Œå¿«ç…§æ–‡ä»¶
    verification_report = {
        'total_original_files': len(original_files),
        'total_snapshot_files': len(snapshot_files),
        'missing_files': [],
        'corrupted_files': [],
        'extra_files': [],
        'error_files': [],
        'successful_files': 0,
        'total_original_size': total_original_size,
        'verified_size': 0
    }

    # æ£€æŸ¥æ¯ä¸ªåŸå§‹æ–‡ä»¶æ˜¯å¦åœ¨å¿«ç…§ä¸­
    processed_count = 0
    for file_path, original_info in original_files.items():
        if show_progress_callback:
            show_progress_callback(processed_count, len(original_files))

        if file_path not in snapshot_files:
            verification_report['missing_files'].append({
                'path': file_path,
                'size': original_info['size'],
                'type': original_info['type']
            })
        else:
            snapshot_info = snapshot_files[file_path]

            if snapshot_info.get('status') == 'error':
                verification_report['error_files'].append({
                    'path': file_path,
                    'error': snapshot_info.get('error', 'æœªçŸ¥é”™è¯¯')
                })
            elif snapshot_info.get('status') == 'found':
                # æ¯”è¾ƒå¤§å°å’Œå†…å®¹
                size_match = original_info['size'] == snapshot_info['size']
                hash_match = True

                if original_info['hash'] and snapshot_info['hash']:
                    hash_match = original_info['hash'] == snapshot_info['hash']

                if size_match and hash_match:
                    verification_report['successful_files'] += 1
                    verification_report['verified_size'] += original_info['size']
                else:
                    verification_report['corrupted_files'].append({
                        'path': file_path,
                        'original_size': original_info['size'],
                        'snapshot_size': snapshot_info['size'],
                        'size_match': size_match,
                        'hash_match': hash_match,
                        'type': original_info['type']
                    })

        processed_count += 1

    # æ£€æŸ¥å¿«ç…§ä¸­æ˜¯å¦æœ‰é¢å¤–çš„æ–‡ä»¶
    for file_path in snapshot_files:
        if file_path not in original_files:
            verification_report['extra_files'].append(file_path)

    # è®¡ç®—å®Œæ•´æ€§ç™¾åˆ†æ¯”
    is_complete = (len(verification_report['missing_files']) == 0 and
                  len(verification_report['corrupted_files']) == 0 and
                  len(verification_report['error_files']) == 0)

    success_rate = (verification_report['successful_files'] / verification_report['total_original_files'] * 100) if verification_report['total_original_files'] > 0 else 0
    size_coverage = (verification_report['verified_size'] / verification_report['total_original_size'] * 100) if verification_report['total_original_size'] > 0 else 0

    verification_report['is_complete'] = is_complete
    verification_report['success_rate'] = success_rate
    verification_report['size_coverage'] = size_coverage

    return is_complete, verification_report


def display_verification_report(report):
    """æ˜¾ç¤ºéªŒè¯æŠ¥å‘Š"""
    print_colored("\n" + "="*60, 'cyan')
    print_colored("ğŸ“‹ å¿«ç…§å®Œæ•´æ€§éªŒè¯æŠ¥å‘Š", 'cyan')
    print_colored("="*60, 'cyan')

    # æ€»ä½“ç»Ÿè®¡
    print_colored(f"ğŸ“ åŸå§‹æ–‡ä»¶æ€»æ•°: {report['total_original_files']}", 'blue')
    print_colored(f"ğŸ“„ å¿«ç…§æ–‡ä»¶æ€»æ•°: {report['total_snapshot_files']}", 'blue')
    print_colored(f"âœ… æˆåŠŸéªŒè¯: {report['successful_files']}", 'green')
    print_colored(f"ğŸ“Š æˆåŠŸç‡: {report['success_rate']:.2f}%", 'green' if report['success_rate'] == 100 else 'yellow')
    print_colored(f"ğŸ’¾ æ•°æ®è¦†ç›–ç‡: {report['size_coverage']:.2f}%", 'green' if report['size_coverage'] == 100 else 'yellow')

    # é—®é¢˜ç»Ÿè®¡
    if report['missing_files']:
        print_colored(f"\nâŒ ç¼ºå¤±æ–‡ä»¶ ({len(report['missing_files'])} ä¸ª):", 'red')
        for file_info in report['missing_files'][:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            print_colored(f"  - {file_info['path']} ({file_info['size']} bytes, {file_info['type']})", 'red')
        if len(report['missing_files']) > 10:
            print_colored(f"  - ... è¿˜æœ‰ {len(report['missing_files']) - 10} ä¸ªç¼ºå¤±æ–‡ä»¶", 'red')

    if report['corrupted_files']:
        print_colored(f"\nğŸ”§ æŸåæ–‡ä»¶ ({len(report['corrupted_files'])} ä¸ª):", 'yellow')
        for file_info in report['corrupted_files'][:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            size_info = f"å¤§å°: {file_info['original_size']} -> {file_info['snapshot_size']}" if not file_info['size_match'] else "å¤§å°åŒ¹é…"
            hash_info = "å†…å®¹ä¸åŒ¹é…" if not file_info['hash_match'] else "å†…å®¹åŒ¹é…"
            print_colored(f"  - {file_info['path']} ({size_info}, {hash_info})", 'yellow')
        if len(report['corrupted_files']) > 5:
            print_colored(f"  - ... è¿˜æœ‰ {len(report['corrupted_files']) - 5} ä¸ªæŸåæ–‡ä»¶", 'yellow')

    if report['error_files']:
        print_colored(f"\nâš ï¸  é”™è¯¯æ–‡ä»¶ ({len(report['error_files'])} ä¸ª):", 'red')
        for file_info in report['error_files'][:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            print_colored(f"  - {file_info['path']}: {file_info['error']}", 'red')
        if len(report['error_files']) > 5:
            print_colored(f"  - ... è¿˜æœ‰ {len(report['error_files']) - 5} ä¸ªé”™è¯¯æ–‡ä»¶", 'red')

    if report['extra_files']:
        print_colored(f"\nâ• å¿«ç…§ä¸­çš„é¢å¤–æ–‡ä»¶ ({len(report['extra_files'])} ä¸ª):", 'blue')
        for file_path in report['extra_files'][:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            print_colored(f"  - {file_path}", 'blue')
        if len(report['extra_files']) > 5:
            print_colored(f"  - ... è¿˜æœ‰ {len(report['extra_files']) - 5} ä¸ªé¢å¤–æ–‡ä»¶", 'blue')

    # ç»“è®º
    print_colored("\n" + "="*60, 'cyan')
    if report['is_complete']:
        print_colored("ğŸ‰ éªŒè¯ç»“æœ: å¿«ç…§å®Œæ•´ï¼Œæ‰€æœ‰æ–‡ä»¶éƒ½å·²æ­£ç¡®æ‰“åŒ…ï¼", 'green')
    else:
        print_colored("âš ï¸  éªŒè¯ç»“æœ: å¿«ç…§ä¸å®Œæ•´ï¼Œå‘ç°é—®é¢˜éœ€è¦å¤„ç†ï¼", 'red')
    print_colored("="*60, 'cyan')


def validate_snapshot_file(file_path):
    """éªŒè¯å¿«ç…§æ–‡ä»¶çš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§"""
    if not os.path.isfile(file_path):
        return False, "æ–‡ä»¶ä¸å­˜åœ¨"
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            
            if first_line == "COMPRESSED":
                # å‹ç¼©æ ¼å¼éªŒè¯
                compressed_content = f.read()
                if ':' in compressed_content:
                    method, encoded_data = compressed_content.split(':', 1)
                    if method not in ['LZMA', 'BZ2', 'ZLIB', 'RAW']:
                        return False, f"ä¸æ”¯æŒçš„å‹ç¼©æ–¹æ³•: {method}"
                    
                    # éªŒè¯base85ç¼–ç 
                    try:
                        base64.b85decode(encoded_data.encode('ascii'))
                    except (ValueError, base64.binascii.Error):
                        return False, "Base85ç¼–ç æ ¼å¼é”™è¯¯"
                
                return True, "å‹ç¼©æ ¼å¼éªŒè¯é€šè¿‡"
                
            else:
                # æ™®é€šæ–‡æœ¬æ ¼å¼éªŒè¯
                content = first_line + f.read()
                lines = content.split('\n')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°
                file_markers = [line for line in lines if 
                               line.startswith('@') and len(line) > 1 and 
                               not line[1:].strip().startswith(('keyframes', 'media', 'import', 'charset', 'font-face')) and
                               not line[1:].strip().startswith(('app.route', 'staticmethod', 'classmethod', 'property')) and
                               not 'def ' in line and not 'class ' in line]
                
                if not file_markers:
                    return False, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ–‡ä»¶æ ‡è®°"
                
                return True, "æ–‡æœ¬æ ¼å¼éªŒè¯é€šè¿‡"
                
    except UnicodeDecodeError:
        return False, "æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œä¸æ˜¯æœ‰æ•ˆçš„UTF-8æ–‡æœ¬æ–‡ä»¶"
    except Exception as e:
        return False, f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"


def print_colored(text, color):
    """è·¨å¹³å°å½©è‰²æ‰“å°æ–‡æœ¬ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
    try:
        if platform.system() == 'Windows':
            try:
                import colorama
                colorama.init(autoreset=True)  # è‡ªåŠ¨é‡ç½®é¢œè‰²
                colors = {
                    'red': colorama.Fore.RED,
                    'green': colorama.Fore.GREEN,
                    'yellow': colorama.Fore.YELLOW,
                    'blue': colorama.Fore.BLUE,
                    'magenta': colorama.Fore.MAGENTA,
                    'cyan': colorama.Fore.CYAN,
                    'end': colorama.Style.RESET_ALL
                }
                print(f"{colors.get(color, '')}{text}{colors['end']}")
            except ImportError:
                print(text)  # æ²¡æœ‰å®‰è£…coloramaåˆ™ä½¿ç”¨æ™®é€šæ–‡æœ¬
        else:
            colors = {
                'red': '\033[91m',
                'green': '\033[92m',
                'yellow': '\033[93m',
                'blue': '\033[94m',
                'magenta': '\033[95m',
                'cyan': '\033[96m',
                'end': '\033[0m'
            }
            print(f"{colors.get(color, '')}{text}{colors['end']}")
    except Exception:
        # å¦‚æœå½©è‰²æ‰“å°å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæ‰“å°
        print(text)


def get_safe_path(path):
    """è·å–å®‰å…¨çš„è·¨å¹³å°è·¯å¾„"""
    # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ï¼Œç„¶åè½¬æ¢ä¸ºå­—ç¬¦ä¸²
    return str(Path(path).resolve())

def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤å½“å‰å¹³å°ä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§"""
    import re
    
    # è·å–å¹³å°ä¿¡æ¯
    platform_info = get_platform_info()
    
    # æ ¹æ®å¹³å°æ„å»ºæ— æ•ˆå­—ç¬¦æ­£åˆ™è¡¨è¾¾å¼
    invalid_chars_str = platform_info['invalid_chars']
    # è½¬ä¹‰æ­£åˆ™è¡¨è¾¾å¼ç‰¹æ®Šå­—ç¬¦
    escaped_chars = re.escape(invalid_chars_str)
    invalid_chars_pattern = f'[{escaped_chars}]'
    
    # æ›¿æ¢ä¸åˆæ³•å­—ç¬¦ä¸ºä¸‹åˆ’çº¿
    sanitized = re.sub(invalid_chars_pattern, '_', filename)
    
    # å¤„ç†è¿ç»­çš„ä¸‹åˆ’çº¿ï¼Œæ›¿æ¢ä¸ºå•ä¸ªä¸‹åˆ’çº¿
    sanitized = re.sub(r'_+', '_', sanitized)
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºæ ¼å’Œç‚¹ï¼ˆWindowsè¦æ±‚ï¼‰
    sanitized = sanitized.strip(' .')
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºä¿ç•™åç§°ï¼ˆä¸»è¦é’ˆå¯¹Windowsï¼‰
    if platform_info['reserved_names']:
        name_without_ext = os.path.splitext(sanitized)[0].upper()
        if name_without_ext in platform_info['reserved_names']:
            sanitized = f"_{sanitized}"
    
    # ç¡®ä¿æ–‡ä»¶åä¸ä¸ºç©º
    if not sanitized:
        sanitized = "unnamed_file"
    
    # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    max_length = min(platform_info['max_filename_length'], 200)  # ä½¿ç”¨å¹³å°é™åˆ¶å’Œå®‰å…¨é™åˆ¶çš„è¾ƒå°å€¼
    if len(sanitized) > max_length:
        name, ext = os.path.splitext(sanitized)
        # ç¡®ä¿æˆªæ–­åä»ç„¶æœ‰ç©ºé—´ç»™æ‰©å±•å
        max_name_length = max_length - len(ext)
        if max_name_length > 0:
            sanitized = name[:max_name_length] + ext
        else:
            # å¦‚æœæ‰©å±•åå¤ªé•¿ï¼Œåªä¿ç•™æˆªæ–­çš„åç§°
            sanitized = name[:max_length]
    
    return sanitized

def get_platform_info():
    """è·å–å½“å‰å¹³å°ä¿¡æ¯ï¼Œç”¨äºè·¯å¾„å¤„ç†ä¼˜åŒ–"""
    system = platform.system().lower()
    
    # è·å–æ–‡ä»¶ç³»ç»Ÿä¿¡æ¯
    filesystem_info = {}
    try:
        if system == 'windows':
            # Windowsç‰¹å®šä¿¡æ¯
            filesystem_info.update({
                'case_sensitive': False,
                'reserved_names': {'CON', 'PRN', 'AUX', 'NUL', 'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9', 'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9'},
                'invalid_chars': '<>:"|?*',
                'max_filename_length': 255,
                'max_path_length': 260
            })
        else:
            # Unix-likeç³»ç»Ÿ - ä¸ºäº†è·¨å¹³å°å…¼å®¹æ€§ï¼Œä½¿ç”¨Windowsçš„é™åˆ¶
            filesystem_info.update({
                'case_sensitive': True,
                'reserved_names': set(),  # Unixç³»ç»Ÿæ²¡æœ‰ä¿ç•™åï¼Œä½†ä¸ºäº†å…¼å®¹æ€§å¯ä»¥æ£€æŸ¥Windowsä¿ç•™å
                'invalid_chars': '<>:"|?*\0',  # åŒ…å«Windowsä¸å…¼å®¹å­—ç¬¦ä»¥ç¡®ä¿è·¨å¹³å°å…¼å®¹
                'max_filename_length': 255,
                'max_path_length': 4096
            })
    except Exception:
        # é»˜è®¤å€¼
        filesystem_info = {
            'case_sensitive': system != 'windows',
            'reserved_names': set(),
            'invalid_chars': '<>:"|?*\0',  # ç»Ÿä¸€ä½¿ç”¨Windowsé™åˆ¶ä»¥ç¡®ä¿è·¨å¹³å°å…¼å®¹
            'max_filename_length': 255,
            'max_path_length': 260 if system == 'windows' else 4096
        }
    
    return {
        'system': system,
        'is_windows': system == 'windows',
        'is_macos': system == 'darwin',
        'is_linux': system == 'linux',
        'path_sep': os.sep,
        'alt_path_sep': os.altsep,
        **filesystem_info
    }

def diagnose_platform_compatibility():
    """è¯Šæ–­å½“å‰å¹³å°çš„å…¼å®¹æ€§å¹¶æä¾›å»ºè®®"""
    info = get_platform_info()
    
    print_colored("=== å¹³å°å…¼å®¹æ€§è¯Šæ–­ ===", 'cyan')
    print_colored(f"æ“ä½œç³»ç»Ÿ: {info['system'].title()}", 'blue')
    print_colored(f"è·¯å¾„åˆ†éš”ç¬¦: '{info['path_sep']}'", 'blue')
    print_colored(f"å¤‡ç”¨è·¯å¾„åˆ†éš”ç¬¦: {info['alt_path_sep']}", 'blue')
    print_colored(f"æ–‡ä»¶ç³»ç»Ÿå¤§å°å†™æ•æ„Ÿ: {info['case_sensitive']}", 'blue')
    print_colored(f"æœ€å¤§æ–‡ä»¶åé•¿åº¦: {info['max_filename_length']}", 'blue')
    print_colored(f"æœ€å¤§è·¯å¾„é•¿åº¦: {info['max_path_length']}", 'blue')
    
    if info['is_windows']:
        print_colored("Windowsç‰¹å®šæ³¨æ„äº‹é¡¹:", 'yellow')
        print_colored("- æ–‡ä»¶åä¸èƒ½åŒ…å«: < > : \" | ? * \\ /", 'yellow')
        print_colored("- é¿å…ä½¿ç”¨ä¿ç•™åç§°: CON, PRN, AUX, NUL, COM1-9, LPT1-9", 'yellow')
        print_colored("- è·¯å¾„é•¿åº¦é™åˆ¶è¾ƒä¸¥æ ¼ (260å­—ç¬¦)", 'yellow')
        
        # æ£€æŸ¥colorama
        try:
            import colorama
            print_colored("âœ… colorama å·²å®‰è£…ï¼Œæ”¯æŒå½©è‰²è¾“å‡º", 'green')
        except ImportError:
            print_colored("âš ï¸  å»ºè®®å®‰è£… colorama ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºä½“éªŒ: pip install colorama", 'yellow')
    
    elif info['is_macos']:
        print_colored("macOSç‰¹å®šæ³¨æ„äº‹é¡¹:", 'yellow')
        print_colored("- æ–‡ä»¶ç³»ç»Ÿé€šå¸¸ä¸åŒºåˆ†å¤§å°å†™ï¼ˆé™¤éä½¿ç”¨APFSåŒºåˆ†å¤§å°å†™æ ¼å¼ï¼‰", 'yellow')
        print_colored("- æ”¯æŒUnicodeæ–‡ä»¶å", 'yellow')
        print_colored("- ä¸ºç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ï¼Œåº”ç”¨Windowsæ–‡ä»¶åé™åˆ¶", 'yellow')
        
    elif info['is_linux']:
        print_colored("Linuxç‰¹å®šæ³¨æ„äº‹é¡¹:", 'yellow')
        print_colored("- æ–‡ä»¶ç³»ç»ŸåŒºåˆ†å¤§å°å†™", 'yellow')
        print_colored("- æ”¯æŒUnicodeæ–‡ä»¶å", 'yellow')
        print_colored("- ä¸ºç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ï¼Œåº”ç”¨Windowsæ–‡ä»¶åé™åˆ¶", 'yellow')
    
    print_colored("=== è¯Šæ–­å®Œæˆ ===", 'cyan')
    return info

def normalize_path_for_restore(stored_path):
    """å°†å¿«ç…§ä¸­å­˜å‚¨çš„è·¯å¾„è§„èŒƒåŒ–ä¸ºå½“å‰ç³»ç»Ÿçš„è·¯å¾„æ ¼å¼"""
    # å°†å­˜å‚¨çš„Unixé£æ ¼è·¯å¾„è½¬æ¢ä¸ºå½“å‰ç³»ç»Ÿè·¯å¾„
    # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§
    path_obj = Path(stored_path.replace('/', os.sep))
    return str(path_obj)

def sanitize_file_path(file_path):
    """æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†Windowsä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§"""
    # è·å–å¹³å°ä¿¡æ¯
    platform_info = get_platform_info()
    
    # é¦–å…ˆè§„èŒƒåŒ–è·¯å¾„æ ¼å¼
    normalized_path = normalize_path_for_restore(file_path)
    
    # ä½¿ç”¨ Path å¯¹è±¡åˆ†å‰²è·¯å¾„ï¼Œæ›´å¯é 
    path_obj = Path(normalized_path)
    path_parts = path_obj.parts
    
    # æ¸…ç†æ¯ä¸ªè·¯å¾„éƒ¨åˆ†
    sanitized_parts = []
    for part in path_parts:
        if part and part not in ('.', '..', '/'):  # è·³è¿‡ç©ºå­—ç¬¦ä¸²ã€ç›¸å¯¹è·¯å¾„æ ‡è®°å’Œæ ¹ç›®å½•
            sanitized_part = sanitize_filename(part)
            sanitized_parts.append(sanitized_part)
    
    # é‡æ–°ç»„åˆè·¯å¾„
    result_path = os.sep.join(sanitized_parts)
    
    # æ£€æŸ¥è·¯å¾„é•¿åº¦æ˜¯å¦è¶…è¿‡å¹³å°é™åˆ¶
    if len(result_path) > platform_info['max_path_length']:
        print_colored(f"è­¦å‘Š: è·¯å¾„é•¿åº¦è¶…è¿‡å¹³å°é™åˆ¶ï¼Œå°†è¢«æˆªæ–­: {result_path[:50]}...", 'yellow')
        # ç®€å•æˆªæ–­ç­–ç•¥ï¼Œä¿ç•™æ–‡ä»¶æ‰©å±•å
        if '.' in result_path:
            name, ext = os.path.splitext(result_path)
            max_name_length = platform_info['max_path_length'] - len(ext) - 10  # ç•™ä¸€äº›ç¼“å†²
            result_path = name[:max_name_length] + ext
        else:
            result_path = result_path[:platform_info['max_path_length'] - 10]
    
    return result_path


def validate_path(path):
    """éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(path):
        print_colored(f"é”™è¯¯: è·¯å¾„ '{path}' ä¸å­˜åœ¨", 'red')
        return False
    return True


def calculate_file_checksum(file_path, algorithm='sha256'):
    """è®¡ç®—æ–‡ä»¶çš„æ ¡éªŒå’Œ"""
    try:
        hash_func = hashlib.new(algorithm)
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_func.update(chunk)
        return hash_func.hexdigest()
    except Exception as e:
        print_colored(f"è­¦å‘Š: è®¡ç®—æ–‡ä»¶ {file_path} æ ¡éªŒå’Œæ—¶å‡ºé”™: {str(e)}", 'yellow')
        return None


def verify_file_integrity(original_path, restored_path):
    """éªŒè¯æ¢å¤æ–‡ä»¶çš„å®Œæ•´æ€§"""
    if not os.path.exists(restored_path):
        return False, "æ¢å¤æ–‡ä»¶ä¸å­˜åœ¨"
    
    original_checksum = calculate_file_checksum(original_path)
    restored_checksum = calculate_file_checksum(restored_path)
    
    if original_checksum is None or restored_checksum is None:
        return False, "æ— æ³•è®¡ç®—æ ¡éªŒå’Œ"
    
    if original_checksum == restored_checksum:
        return True, "æ ¡éªŒå’ŒåŒ¹é…"
    else:
        return False, f"æ ¡éªŒå’Œä¸åŒ¹é…: åŸå§‹={original_checksum[:8]}, æ¢å¤={restored_checksum[:8]}"


def show_progress(current, total, prefix=""):
    """æ˜¾ç¤ºè¿›åº¦æ¡"""
    percent = int(current * 100 / total) if total > 0 else 0
    bar_length = 50
    filled_length = int(bar_length * current // total) if total > 0 else 0
    bar = '#' * filled_length + '-' * (bar_length - filled_length)
    print(f"\r{prefix} [{bar}] {percent}%", end='')
    if current == total:
        print()


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æ–‡ä»¶å¿«ç…§å·¥å…· - æ”¯æŒé«˜å‹ç¼©ç‡å¤‡ä»½å’Œæ¢å¤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # äº¤äº’å¼æ¨¡å¼
  python FolderSnapshot.py
  
  # åˆ›å»ºå‹ç¼©å¿«ç…§
  python FolderSnapshot.py --type compress --input /path/to/folder
  
  # åˆ›å»ºæ— å‹ç¼©å¿«ç…§
  python FolderSnapshot.py --type snapshot --input /path/to/folder
  
  # æ¢å¤å¿«ç…§
  python FolderSnapshot.py --type restore --input snapshot.txt --output /restore/path
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python FolderSnapshot.py --type compress --input /path/to/folder --output backup.txt
  
  # é™é»˜æ¨¡å¼ï¼ˆæ— è¿›åº¦æ¡ï¼‰
  python FolderSnapshot.py --type compress --input /path/to/folder --quiet
        """
    )
    
    parser.add_argument(
        '--type', '-t',
        choices=['snapshot', 'compress', 'restore'],
        help='æ“ä½œç±»å‹: snapshot=åˆ›å»ºæ— å‹ç¼©å¿«ç…§, compress=åˆ›å»ºå‹ç¼©å¿«ç…§, restore=æ¢å¤å¿«ç…§'
    )
    
    parser.add_argument(
        '--input', '-i',
        help='è¾“å…¥è·¯å¾„: å¯¹äºsnapshot/compressæ˜¯æºæ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„ï¼Œå¯¹äºrestoreæ˜¯å¿«ç…§æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--output', '-o',
        help='è¾“å‡ºè·¯å¾„: å¯¹äºsnapshot/compressæ˜¯è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œå¯¹äºrestoreæ˜¯æ¢å¤ç›®æ ‡æ–‡ä»¶å¤¹'
    )
    
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¿›åº¦æ¡'
    )
    
    parser.add_argument(
        '--version', '-v',
        action='version',
        version='FolderSnapshot v3.2 - è·¨å¹³å°å…¼å®¹æ–‡ä»¶å¿«ç…§å·¥å…·'
    )
    
    return parser.parse_args()


def get_custom_output_path(input_path, operation_type):
    """åœ¨äº¤äº’å¼æ¨¡å¼ä¸­è·å–è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„"""
    # ç”Ÿæˆé»˜è®¤è·¯å¾„ä½œä¸ºæç¤º
    default_path = generate_default_output_path(input_path, operation_type)
    
    print_colored(f"\nğŸ’¡ é»˜è®¤è¾“å‡ºè·¯å¾„: {default_path}", 'blue')
    custom_path = input("è¯·è¾“å…¥è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„): ").strip()
    
    if not custom_path:
        # ç”¨æˆ·ç›´æ¥å›è½¦ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        return default_path
    
    # å¤„ç†ç”¨æˆ·è¾“å…¥çš„è·¯å¾„
    custom_path = get_safe_path(custom_path)
    
    # å¦‚æœç”¨æˆ·è¾“å…¥çš„æ˜¯ç›®å½•ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
    if os.path.isdir(custom_path):
        filename = os.path.basename(default_path)
        custom_path = os.path.join(custom_path, filename)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(custom_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # é¿å…æ–‡ä»¶å†²çª
    custom_path = get_unique_filepath(custom_path)
    
    return custom_path


def run_interactive_mode():
    """è¿è¡Œäº¤äº’å¼æ¨¡å¼"""
    print_colored("=== æ–‡ä»¶å¿«ç…§å·¥å…· (v3.2 - è·¨å¹³å°ä¼˜åŒ–ç‰ˆ) ===", 'blue')
    print("1. åˆ›å»ºå¿«ç…§æ–‡ä»¶ (æ— å‹ç¼©ï¼Œæ”¯æŒæ‰€æœ‰æ–‡ä»¶ç±»å‹)")
    print("2. åˆ›å»ºé«˜å‹ç¼©ç‡å¿«ç…§æ–‡ä»¶ (LZMA)")
    print("3. ä»å¿«ç…§æ–‡ä»¶æ¢å¤ (è‡ªåŠ¨è¯†åˆ«å‹ç¼©ç±»å‹)")
    print("4. éªŒè¯å¿«ç…§å®Œæ•´æ€§ (å¿«é€Ÿ)")
    print("5. éªŒè¯å¿«ç…§å®Œæ•´æ€§ (è¯¦ç»†)")
    print("6. å¹³å°å…¼å®¹æ€§è¯Šæ–­")
    print_colored("0. é€€å‡º", 'yellow')
    
    while True:
        choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (1/2/3/4/5/6/0): ").strip()

        if choice == "0":
            print_colored("å·²é€€å‡ºç¨‹åº", 'green')
            break

        if choice not in ("1", "2", "3", "4", "5", "6"):
            print_colored("æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥!", 'red')
            continue
            
        try:
            def progress_callback(current, total):
                show_progress(current, total, "å¤„ç†è¿›åº¦:")

            if choice == "1":
                # åˆ›å»ºæ— å‹ç¼©å¿«ç…§
                path = input("è¯·è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(path): 
                    continue
                
                # è·å–è¾“å‡ºè·¯å¾„
                output_path = get_custom_output_path(path, 'snapshot')
                print_colored(f"ğŸ“ å°†ä¿å­˜åˆ°: {output_path}", 'blue')
                
                # åˆ›å»ºå¿«ç…§
                temp_output_file = gather_files_to_txt(path, show_progress_callback=progress_callback)
                
                # ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„
                import shutil
                shutil.move(str(temp_output_file), output_path)
                
                print() # æ¢è¡Œ
                print_colored(f"âœ… æ“ä½œå®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_path}", 'green')
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                file_size = os.path.getsize(output_path)
                print_colored(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size/1024:.2f} KB", 'blue')

            elif choice == "2":
                # åˆ›å»ºå‹ç¼©å¿«ç…§
                path = input("è¯·è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(path): 
                    continue
                
                # è·å–è¾“å‡ºè·¯å¾„
                output_path = get_custom_output_path(path, 'compress')
                print_colored(f"ğŸ“ å°†ä¿å­˜åˆ°: {output_path}", 'blue')
                
                # åˆ›å»ºå‹ç¼©å¿«ç…§
                temp_output_file = gather_files_to_txt_compressed(path, show_progress_callback=progress_callback)
                
                # ç§»åŠ¨åˆ°æŒ‡å®šè·¯å¾„
                import shutil
                shutil.move(str(temp_output_file), output_path)
                
                print() # æ¢è¡Œ
                print_colored(f"âœ… æ“ä½œå®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_path}", 'green')
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                file_size = os.path.getsize(output_path)
                print_colored(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size/1024:.2f} KB", 'blue')
                
            elif choice == "3":
                # æ¢å¤å¿«ç…§
                txt_path = input("è¯·è¾“å…¥å¿«ç…§æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(txt_path): 
                    continue
                
                # è·å–æ¢å¤ç›®æ ‡è·¯å¾„
                print_colored(f"\nğŸ’¡ è¯·æŒ‡å®šæ¢å¤ç›®æ ‡ç›®å½•", 'blue')
                output_folder = input("è¯·è¾“å…¥è¦æ¢å¤åˆ°çš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
                
                if not output_folder:
                    print_colored("é”™è¯¯: å¿…é¡»æŒ‡å®šæ¢å¤ç›®æ ‡è·¯å¾„!", 'red')
                    continue
                
                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                os.makedirs(output_folder, exist_ok=True)
                
                print_colored(f"ğŸ“ å°†æ¢å¤åˆ°: {output_folder}", 'blue')
                restore_files_from_txt(txt_path, output_folder)  # è‡ªåŠ¨åˆ¤æ–­æ–‡ä»¶ç±»å‹

            elif choice == "4":
                # å¿«é€ŸéªŒè¯å¿«ç…§å®Œæ•´æ€§
                snapshot_path = input("è¯·è¾“å…¥å¿«ç…§æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(snapshot_path):
                    continue

                original_path = input("è¯·è¾“å…¥åŸå§‹æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(original_path):
                    continue

                print_colored(f"âš¡ æ­£åœ¨è¿›è¡Œå¿«é€ŸéªŒè¯...", 'blue')
                is_complete, report = verify_snapshot_integrity_fast(snapshot_path, original_path, progress_callback)
                display_fast_verification_report(report)

            elif choice == "5":
                # è¯¦ç»†éªŒè¯å¿«ç…§å®Œæ•´æ€§
                snapshot_path = input("è¯·è¾“å…¥å¿«ç…§æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(snapshot_path):
                    continue

                original_path = input("è¯·è¾“å…¥åŸå§‹æ–‡ä»¶å¤¹æˆ–æ–‡ä»¶è·¯å¾„: ").strip()
                if not validate_path(original_path):
                    continue

                print_colored(f"ğŸ” æ­£åœ¨è¿›è¡Œè¯¦ç»†éªŒè¯...", 'blue')
                is_complete, report = verify_snapshot_integrity(snapshot_path, original_path, progress_callback)
                display_verification_report(report)

            elif choice == "6":
                # å¹³å°å…¼å®¹æ€§è¯Šæ–­
                diagnose_platform_compatibility()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")

        except Exception as e:
            print_colored(f"\nâŒ å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}", 'red')
            import traceback
            if input("æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯? (y/N): ").strip().lower() == 'y':
                traceback.print_exc()
            continue


def generate_default_output_path(input_path, operation_type):
    """ç”Ÿæˆé»˜è®¤è¾“å‡ºè·¯å¾„"""
    from datetime import datetime
    
    input_path = Path(input_path)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if input_path.is_file():
        # å•ä¸ªæ–‡ä»¶
        base_name = input_path.stem
        if operation_type == 'compress':
            return str(input_path.parent / f"{base_name}_compressed_{timestamp}.txt")
        else:
            return str(input_path.parent / f"{base_name}_snapshot_{timestamp}.txt")
    else:
        # ç›®å½•
        folder_name = input_path.name
        if operation_type == 'compress':
            return str(input_path.parent / f"{folder_name}_compressed_{timestamp}.txt")
        else:
            return str(input_path.parent / f"{folder_name}_snapshot_{timestamp}.txt")


def run_command_line_mode(args):
    """è¿è¡Œå‘½ä»¤è¡Œæ¨¡å¼"""
    # è®¾ç½®è¿›åº¦å›è°ƒ
    progress_callback = None if args.quiet else lambda current, total: show_progress(current, total, "å¤„ç†è¿›åº¦:")
    
    try:
        if args.type in ['snapshot', 'compress']:
            # åˆ›å»ºå¿«ç…§
            if not args.input:
                print_colored("é”™è¯¯: éœ€è¦æŒ‡å®šè¾“å…¥è·¯å¾„ --input", 'red')
                return False
                
            if not validate_path(args.input):
                return False
            
            print_colored(f"æ­£åœ¨å¤„ç†: {args.input}", 'blue')
            
            if args.type == 'snapshot':
                # åˆ›å»ºæ— å‹ç¼©å¿«ç…§
                output_file = gather_files_to_txt(args.input, show_progress_callback=progress_callback)
            else:
                # åˆ›å»ºå‹ç¼©å¿«ç…§
                output_file = gather_files_to_txt_compressed(args.input, show_progress_callback=progress_callback)
            
            # å¤„ç†è¾“å‡ºè·¯å¾„
            if args.output:
                import shutil
                final_output = get_safe_path(args.output)
                
                # å¦‚æœè¾“å‡ºè·¯å¾„æ˜¯ç›®å½•ï¼Œç”Ÿæˆæ–‡ä»¶å
                if os.path.isdir(final_output):
                    filename = os.path.basename(str(output_file))
                    final_output = os.path.join(final_output, filename)
                
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_dir = os.path.dirname(final_output)
                if output_dir:
                    os.makedirs(output_dir, exist_ok=True)
                
                # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                final_output = get_unique_filepath(final_output)
                
                shutil.move(str(output_file), final_output)
                output_file = final_output
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œä½¿ç”¨æ›´å‹å¥½çš„é»˜è®¤å‘½å
                default_output = generate_default_output_path(args.input, args.type)
                default_output = get_unique_filepath(default_output)
                
                import shutil
                shutil.move(str(output_file), default_output)
                output_file = default_output
            
            if not args.quiet:
                print() # æ¢è¡Œ
            print_colored(f"âœ… æ“ä½œå®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file}", 'green')
            
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°ä¿¡æ¯
            if not args.quiet:
                file_size = os.path.getsize(output_file)
                print_colored(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size/1024:.2f} KB", 'blue')
            
            return True
            
        elif args.type == 'restore':
            # æ¢å¤å¿«ç…§
            if not args.input:
                print_colored("é”™è¯¯: éœ€è¦æŒ‡å®šå¿«ç…§æ–‡ä»¶è·¯å¾„ --input", 'red')
                return False
                
            if not args.output:
                print_colored("é”™è¯¯: éœ€è¦æŒ‡å®šæ¢å¤ç›®æ ‡è·¯å¾„ --output", 'red')
                return False
                
            if not validate_path(args.input):
                return False
            
            print_colored(f"æ­£åœ¨æ¢å¤: {args.input} â†’ {args.output}", 'blue')
            restore_files_from_txt(args.input, args.output)
            return True
            
    except Exception as e:
        print_colored(f"âŒ æ“ä½œå¤±è´¥: {str(e)}", 'red')
        return False


def create_restore_report(success_count, error_count, error_details, output_folder):
    """åˆ›å»ºè¯¦ç»†çš„æ¢å¤æŠ¥å‘Šæ–‡ä»¶"""
    report_path = os.path.join(output_folder, "restore_report.txt")
    
    try:
        with open(report_path, 'w', encoding='utf-8') as report_file:
            report_file.write("=== æ–‡ä»¶å¤¹å¿«ç…§æ¢å¤æŠ¥å‘Š ===\n\n")
            report_file.write(f"æ¢å¤æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            report_file.write(f"ç›®æ ‡ç›®å½•: {output_folder}\n")
            report_file.write(f"æˆåŠŸæ–‡ä»¶: {success_count}\n")
            report_file.write(f"å¤±è´¥æ–‡ä»¶: {error_count}\n")
            report_file.write(f"æˆåŠŸç‡: {(success_count/(success_count + error_count)*100):.2f}%\n\n")
            
            if error_count > 0:
                report_file.write("=== é”™è¯¯è¯¦æƒ… ===\n")
                for i, error in enumerate(error_details, 1):
                    report_file.write(f"{i}. {error}\n")
            
            report_file.write("\n=== æ¢å¤æ‘˜è¦ ===\n")
            if error_count == 0:
                report_file.write("âœ… æ‰€æœ‰æ–‡ä»¶æ¢å¤æˆåŠŸï¼")
            else:
                report_file.write(f"âš ï¸  {error_count} ä¸ªæ–‡ä»¶æ¢å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯è¯¦æƒ…ã€‚")
        
        print_colored(f"æ¢å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}", 'blue')
        return True
        
    except Exception as e:
        print_colored(f"è­¦å‘Š: åˆ›å»ºæ¢å¤æŠ¥å‘Šå¤±è´¥: {str(e)}", 'yellow')
        return False

def restore_files_from_old_txt(txt_path, output_folder):
    """ä»æ—§ç‰ˆæœ¬æœªå‹ç¼©çš„æ–‡æœ¬æ–‡ä»¶æ¢å¤åŸå§‹æ–‡ä»¶"""
    if not os.path.isfile(txt_path):
        print_colored("é”™è¯¯: è¾“å…¥çš„è·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶!", 'red')
        return
    
    # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œè·³è¿‡æ ¼å¼æ ‡è¯†è¡Œ
    with open(txt_path, 'r', encoding='utf-8') as f:
        content = f.read().split('\n', 2)[2]  # è·³è¿‡å‰ä¸¤è¡Œæ ¼å¼æ ‡è¯†
    
    os.makedirs(output_folder, exist_ok=True)
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡ä»¶å—
    import re
    file_blocks = re.split(r'=== æ–‡ä»¶: (.+?) ===\n', content)[1:]
    
    total_blocks = len(file_blocks) // 2
    if total_blocks == 0:
        print_colored("è­¦å‘Š: æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ–‡ä»¶å—ã€‚", 'yellow')
        return
    
    # æ¢å¤é€»è¾‘
    show_progress(0, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # é”™è¯¯è·Ÿè¸ªå’Œç»Ÿè®¡
    success_count = 0
    error_count = 0
    error_details = []
    
    for i in range(0, len(file_blocks), 2):
        if i + 1 >= len(file_blocks):
            break
            
        file_path = file_blocks[i].strip().replace('\\', '/')
        file_content = file_blocks[i+1].split('\n' + "="*50)[0]
        
        # æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†Windowsä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§
        sanitized_file_path = sanitize_file_path(file_path)
        # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è¿æ¥
        full_path = str(Path(output_folder) / sanitized_file_path)
        
        try:
            # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            parent_dir = os.path.dirname(full_path)
            if parent_dir:  # åªæœ‰å½“çˆ¶ç›®å½•ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
                os.makedirs(parent_dir, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶å†…å®¹
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(file_content)
            success_count += 1
            
        except OSError as e:
            # æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ï¼ˆæƒé™ã€ç£ç›˜ç©ºé—´ç­‰ï¼‰
            error_msg = f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {sanitized_file_path} - {str(e)}"
            if e.errno == 13:  # Permission denied
                error_msg += " (æƒé™è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™æˆ–ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ)"
            elif e.errno == 28:  # No space left on device
                error_msg += " (ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†ç£ç›˜ç©ºé—´)"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except Exception as e:
            # å…¶ä»–æœªçŸ¥é”™è¯¯
            error_msg = f"æœªçŸ¥é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
        
        show_progress(i // 2 + 1, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # ç”Ÿæˆæ¢å¤æŠ¥å‘Š
    print()
    print_colored(f"æ¢å¤å®Œæˆ: {success_count} ä¸ªæ–‡ä»¶æˆåŠŸ, {error_count} ä¸ªæ–‡ä»¶å¤±è´¥", 
                 'green' if error_count == 0 else 'yellow')
    
    if error_count > 0:
        print_colored("\né”™è¯¯è¯¦æƒ…:", 'yellow')
        for error in error_details[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print_colored(f"  - {error}", 'yellow')
        if error_count > 5:
            print_colored(f"  - ... è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯", 'yellow')
    
    # åˆ›å»ºè¯¦ç»†çš„æ¢å¤æŠ¥å‘Šæ–‡ä»¶
    create_restore_report(success_count, error_count, error_details, output_folder)
    
    print_colored(f"æ–‡ä»¶å·²ä» {txt_path} æ¢å¤åˆ° {output_folder}", 'green')

def restore_files_from_old_compressed_txt(txt_path, output_folder):
    """ä»æ—§ç‰ˆæœ¬å‹ç¼©çš„æ–‡æœ¬æ–‡ä»¶æ¢å¤åŸå§‹æ–‡ä»¶"""
    if not os.path.isfile(txt_path):
        print_colored("é”™è¯¯: è¾“å…¥çš„è·¯å¾„ä¸æ˜¯æœ‰æ•ˆçš„æ–‡æœ¬æ–‡ä»¶!", 'red')
        return

    # è¯»å–å‹ç¼©å†…å®¹
    print("æ­£åœ¨è¯»å–å¹¶è§£å‹ç¼©æ–‡ä»¶...")
    with open(txt_path, 'r', encoding='utf-8') as f:
        first_line = f.readline().strip()
        if first_line != "=== SNAPSHOT_FORMAT: COMPRESSED ===":
            print_colored("é”™è¯¯: æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®!", 'red')
            return
        f.readline()  # è·³è¿‡ç©ºè¡Œ
        compressed_content = f.read()
    
    try:
        # è§£å‹å†…å®¹
        compressed = base64.b85decode(compressed_content.encode('utf-8'))
        decompressed_content = lzma.decompress(compressed).decode('utf-8')
        
        # æ˜¾ç¤ºè§£å‹æ¯”ä¾‹
        compressed_size = len(compressed_content.encode('utf-8'))
        original_size = len(decompressed_content.encode('utf-8'))
        if compressed_size > 0:
            ratio = (original_size / compressed_size) * 100
            print_colored(f"è§£å‹æ¯”ä¾‹: å‹ç¼©æ–‡ä»¶ {compressed_size/1024:.2f} KB â†’ è§£å‹å {original_size/1024:.2f} KB (åŸå§‹å¤§å°çš„ {ratio:.2f}%)", 'blue')
            
    except Exception as e:
        print_colored(f"è§£å‹ç¼©å¤±è´¥: {str(e)}", 'red')
        return
    
    # æ¢å¤æ–‡ä»¶å†…å®¹
    os.makedirs(output_folder, exist_ok=True)
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡ä»¶å—
    import re
    file_blocks = re.split(r'=== æ–‡ä»¶: (.+?) ===\n', decompressed_content)[1:]
    
    total_blocks = len(file_blocks) // 2
    if total_blocks == 0:
        print_colored("è­¦å‘Š: æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ–‡ä»¶å—ã€‚", 'yellow')
        return

    # æ¢å¤é€»è¾‘
    show_progress(0, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # é”™è¯¯è·Ÿè¸ªå’Œç»Ÿè®¡
    success_count = 0
    error_count = 0
    error_details = []
    
    for i in range(0, len(file_blocks), 2):
        if i + 1 >= len(file_blocks):
            break
            
        file_path = file_blocks[i].strip().replace('\\', '/')
        file_content = file_blocks[i+1].split('\n' + "="*50)[0]
        
        # æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†Windowsä¸æ”¯æŒçš„å­—ç¬¦ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§
        sanitized_file_path = sanitize_file_path(file_path)
        # ä½¿ç”¨ Path å¯¹è±¡ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è¿æ¥
        full_path = str(Path(output_folder) / sanitized_file_path)
        
        try:
            # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            parent_dir = os.path.dirname(full_path)
            if parent_dir:  # åªæœ‰å½“çˆ¶ç›®å½•ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
                os.makedirs(parent_dir, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶å†…å®¹
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(file_content)
            success_count += 1
            
        except OSError as e:
            # æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ï¼ˆæƒé™ã€ç£ç›˜ç©ºé—´ç­‰ï¼‰
            error_msg = f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {sanitized_file_path} - {str(e)}"
            if e.errno == 13:  # Permission denied
                error_msg += " (æƒé™è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™æˆ–ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ)"
            elif e.errno == 28:  # No space left on device
                error_msg += " (ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†ç£ç›˜ç©ºé—´)"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
            
        except Exception as e:
            # å…¶ä»–æœªçŸ¥é”™è¯¯
            error_msg = f"æœªçŸ¥é”™è¯¯: {sanitized_file_path} - {str(e)}"
            print_colored(f"è­¦å‘Š: {error_msg}", 'yellow')
            error_count += 1
            error_details.append(error_msg)
        
        show_progress(i // 2 + 1, total_blocks, "æ¢å¤è¿›åº¦:")
    
    # ç”Ÿæˆæ¢å¤æŠ¥å‘Š
    print()
    print_colored(f"æ¢å¤å®Œæˆ: {success_count} ä¸ªæ–‡ä»¶æˆåŠŸ, {error_count} ä¸ªæ–‡ä»¶å¤±è´¥", 
                 'green' if error_count == 0 else 'yellow')
    
    if error_count > 0:
        print_colored("\né”™è¯¯è¯¦æƒ…:", 'yellow')
        for error in error_details[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print_colored(f"  - {error}", 'yellow')
        if error_count > 5:
            print_colored(f"  - ... è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯", 'yellow')
    
    # åˆ›å»ºè¯¦ç»†çš„æ¢å¤æŠ¥å‘Šæ–‡ä»¶
    create_restore_report(success_count, error_count, error_details, output_folder)
    
    print_colored(f"æ–‡ä»¶å·²ä» {txt_path} æ¢å¤åˆ° {output_folder}", 'green')


# ä¸»å‡½æ•°
if __name__ == "__main__":
    # æ£€æŸ¥å¹¶å°è¯•å®‰è£…colorama (ä»…Windows)
    if platform.system() == 'Windows':
        try:
            import colorama
        except ImportError:
            print("æ£€æµ‹åˆ°Windowsç³»ç»Ÿï¼Œå»ºè®®å®‰è£…coloramaä»¥è·å¾—æ›´å¥½çš„å½©è‰²è¾“å‡ºæ”¯æŒ")
            print("å¯ä»¥é€šè¿‡è¿è¡Œ: pip install colorama æ¥å®‰è£…")
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ“ä½œç±»å‹ï¼Œè¿è¡Œäº¤äº’å¼æ¨¡å¼
    if not args.type:
        run_interactive_mode()
    else:
        # è¿è¡Œå‘½ä»¤è¡Œæ¨¡å¼
        success = run_command_line_mode(args)
        sys.exit(0 if success else 1)
